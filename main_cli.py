# batch_translator_cli.py
import argparse
import sys
import os
from pathlib import Path
from typing import Optional, Dict, List, Callable, Any
import threading
import logging
import json

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ë””ë ‰í† ë¦¬ë¥¼ sys.pathì— ì¶”ê°€ (main_gui.pyì™€ ìœ ì‚¬í•˜ê²Œ)
project_root = Path(__file__).resolve().parent.parent
if str(project_root) not in sys.path:
    sys.path.insert(0, str(project_root))

# tqdm ë° ê¸°íƒ€ í•„ìš”í•œ ëª¨ë“ˆ ì„í¬íŠ¸
try:
    from tqdm import tqdm
except ImportError:
    class tqdm: # Fallback tqdm
        def __init__(self, iterable=None, total=None, desc=None, unit="it", leave=True, file=None, bar_format=None):
            self.iterable = iterable
            self.total = total if total is not None else (len(iterable) if hasattr(iterable, '__len__') else None)
            self.desc = desc
            self.unit = unit
            self.n = 0
            self.leave = leave
            self.file = file if file else sys.stderr
            self.bar_format = bar_format

        def __iter__(self):
            if self.iterable is None:
                raise ValueError("iterable is required for tqdm iteration")
            for obj in self.iterable:
                yield obj
                self.update(1)
            if self.leave:
                self.close()

        def update(self, n=1):
            self.n += n
            if self.total:
                percent = int((self.n / self.total) * 100)
                filled_len = int(20 * self.n // self.total)
                bar = '#' * filled_len + '-' * (20 - filled_len)
                status = f"{self.desc or ''}: {percent}%|{bar}| {self.n}/{self.total} [{self.unit}]"
                self.file.write(f"\r{status}")
                self.file.flush()
                if self.n == self.total and self.leave:
                    self.file.write('\n')
                    self.file.flush()

        def close(self):
            if self.total and self.n < self.total and self.leave:
                self.file.write('\n')
                self.file.flush()
            elif self.n == self.total and self.leave:
                pass

        def __enter__(self): return self
        def __exit__(self,et,ev,tb): self.close()
        @staticmethod
        def write(s, file=None, end="\n", nolock=False):
            _file = file if file else sys.stderr
            _file.write(s + end); _file.flush()
        def set_postfix(self, ordered_dict=None, refresh=True, **kwargs):
            postfix_parts = []
            if ordered_dict: postfix_parts.extend([f"{k}={v}" for k, v in ordered_dict.items()])
            if kwargs: postfix_parts.extend([f"{k}={v}" for k, v in kwargs.items()])
            if postfix_parts: Tqdm.write(f"  {', '.join(postfix_parts)}", file=self.file)

Tqdm = tqdm

try:
    from app.app_service import AppService
    from core.dtos import TranslationJobProgressDTO, GlossaryExtractionProgressDTO
    from core.exceptions import BtgException
    from core.github_auth_service import GitHubAuthService
    from core.config.config_manager import ConfigManager
    from infrastructure.logger_config import setup_logger
    from infrastructure.file_handler import (
        read_text_file, get_metadata_file_path, load_metadata,
        _hash_config_for_metadata, delete_file
    )
except ImportError as e:
    print(f"ì˜¤ë¥˜: í•„ìš”í•œ ëª¨ë“ˆì„ ì„í¬íŠ¸í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. PYTHONPATHë¥¼ í™•ì¸í•˜ê±°ë‚˜ "
          f"í”„ë¡œì íŠ¸ ë£¨íŠ¸ì—ì„œ ìŠ¤í¬ë¦½íŠ¸ë¥¼ ì‹¤í–‰í•˜ì„¸ìš”. ({e})")
    sys.exit(1)

cli_logger = setup_logger("btg_cli")

tqdm_instances: Dict[str, Tqdm] = {}
tqdm_lock = threading.Lock()

def cli_translation_progress_callback(dto: TranslationJobProgressDTO):
    global tqdm_instances
    task_id = "translation"

    with tqdm_lock:
        if task_id not in tqdm_instances or tqdm_instances[task_id].total != dto.total_chunks:
            if task_id in tqdm_instances: tqdm_instances[task_id].close()
            if dto.total_chunks > 0 :
                tqdm_instances[task_id] = Tqdm(total=dto.total_chunks, desc="ì²­í¬ ë²ˆì—­", unit="ì²­í¬", leave=False, file=sys.stdout )
            else:
                if task_id in tqdm_instances: del tqdm_instances[task_id]
                return

        tqdm_instance = tqdm_instances.get(task_id)
        if not tqdm_instance: return

        if dto.processed_chunks > tqdm_instance.n :
             update_amount = dto.processed_chunks - tqdm_instance.n
             if update_amount > 0:
                tqdm_instance.update(update_amount)


        postfix_info = {}
        if dto.successful_chunks > 0: postfix_info["ì„±ê³µ"] = dto.successful_chunks
        if dto.failed_chunks > 0: postfix_info["ì‹¤íŒ¨"] = dto.failed_chunks
        if dto.last_error_message: postfix_info["ë§ˆì§€ë§‰ì˜¤ë¥˜"] = dto.last_error_message[:30]

        if postfix_info: tqdm_instance.set_postfix(postfix_info, refresh=True)

        if dto.processed_chunks == dto.total_chunks and dto.total_chunks > 0:
            tqdm_instance.close()
            if task_id in tqdm_instances: del tqdm_instances[task_id]

def cli_translation_status_callback(message: str):
    Tqdm.write(f"ë²ˆì—­ ìƒíƒœ: {message}", file=sys.stdout)


def cli_glossary_extraction_progress_callback(dto: GlossaryExtractionProgressDTO): # í•¨ìˆ˜ëª… ë° DTO ë³€ê²½
    global tqdm_instances
    task_id = "glossary_extraction" # task_id ë³€ê²½

    with tqdm_lock:
        if task_id not in tqdm_instances or tqdm_instances[task_id].total != dto.total_segments: # DTO í•„ë“œëª… ë³€ê²½ (total_sample_chunks -> total_segments)
            if task_id in tqdm_instances: tqdm_instances[task_id].close()
            if dto.total_segments > 0: # DTO í•„ë“œëª… ë³€ê²½
                tqdm_instances[task_id] = Tqdm(total=dto.total_segments, desc="ìš©ì–´ì§‘ ì¶”ì¶œ (í‘œë³¸)", unit="ì„¸ê·¸ë¨¼íŠ¸", leave=False, file=sys.stdout) # ì„¤ëª… ë³€ê²½
            else:
                if task_id in tqdm_instances: del tqdm_instances[task_id] # type: ignore
                return

        tqdm_instance = tqdm_instances.get(task_id)
        if not tqdm_instance: return

        if dto.processed_segments > tqdm_instance.n: # DTO í•„ë“œëª… ë³€ê²½ (processed_sample_chunks -> processed_segments)
            update_amount = dto.processed_segments - tqdm_instance.n # DTO í•„ë“œëª… ë³€ê²½
            if update_amount > 0:
                tqdm_instance.update(update_amount)

        if dto.current_status_message:
            postfix_info = {"ìƒíƒœ": dto.current_status_message}
            if dto.extracted_entries_count > 0: postfix_info["ì¶”ì¶œí•­ëª©"] = dto.extracted_entries_count
            tqdm_instance.set_postfix(postfix_info, refresh=True)

        if dto.processed_segments == dto.total_segments and dto.total_segments > 0: # DTO í•„ë“œëª… ë³€ê²½
            tqdm_instance.close()
            if task_id in tqdm_instances: del tqdm_instances[task_id] # type: ignore


def parse_arguments():
    """ëª…ë ¹ì¤„ ì¸ìˆ˜ë¥¼ íŒŒì‹±í•©ë‹ˆë‹¤."""
    parser = argparse.ArgumentParser(description="BTG - ë°°ì¹˜ ë²ˆì—­ê¸° CLI (4-Tier Refactored)")
    parser.add_argument("input_file", type=Path, help="ë²ˆì—­í•  ì…ë ¥ í…ìŠ¤íŠ¸ íŒŒì¼ ê²½ë¡œ")
    parser.add_argument("-o", "--output_file", type=Path, default=None, help="ë²ˆì—­ ê²°ê³¼ë¥¼ ì €ì¥í•  íŒŒì¼ ê²½ë¡œ (ê¸°ë³¸ê°’: ì…ë ¥íŒŒì¼_translated.txt)")
    parser.add_argument("-c", "--config", type=Path, default="config.json", help="ì„¤ì • íŒŒì¼ ê²½ë¡œ (ê¸°ë³¸ê°’: config.json)")

    auth_group = parser.add_mutually_exclusive_group()
    auth_group.add_argument("--auth-credentials", type=str, default=None, help="Gemini API í‚¤ (ë‹¨ì¼) ë˜ëŠ” Vertex AI ì„œë¹„ìŠ¤ ê³„ì • JSON ë¬¸ìì—´")
    auth_group.add_argument("--auth-credentials-file", type=Path, default=None, help="Vertex AI ì„œë¹„ìŠ¤ ê³„ì • JSON íŒŒì¼ ê²½ë¡œ")
    # ì—¬ëŸ¬ API í‚¤ë¥¼ ìœ„í•œ ì¸ìˆ˜ ì¶”ê°€
    auth_group.add_argument("--api-keys", type=str, default=None, help="ì‰¼í‘œë¡œ êµ¬ë¶„ëœ Gemini API í‚¤ ëª©ë¡ (ì˜ˆ: key1,key2,key3)")

    # Vertex AI ì„¤ì •
    parser.add_argument("--use-vertex-ai", action="store_true", help="Vertex AI APIë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤ (ì„œë¹„ìŠ¤ ê³„ì • í•„ìš”).")
    parser.add_argument("--gcp-project", type=str, default=None, help="Vertex AI ì‚¬ìš© ì‹œ GCP í”„ë¡œì íŠ¸ ID")
    parser.add_argument("--gcp-location", type=str, default=None, help="Vertex AI ì‚¬ìš© ì‹œ GCP ë¦¬ì „")

    # GitHub Copilot ì„¤ì •
    github_group = parser.add_argument_group('GitHub Copilot ì„¤ì •')
    github_group.add_argument("--use-github-copilot", action="store_true", help="GitHub Copilotì„ LLM ë°±ì—”ë“œë¡œ ì‚¬ìš©í•©ë‹ˆë‹¤.")
    github_group.add_argument("--github-copilot-token", type=str, default=None, help="GitHub Copilot ì•¡ì„¸ìŠ¤ í† í°")
    github_group.add_argument("--github-copilot-model", type=str, default="gpt-4o", choices=["gpt-4o", "gpt-4", "gpt-3.5-turbo"], help="GitHub Copilotì—ì„œ ì‚¬ìš©í•  ëª¨ë¸ (ê¸°ë³¸ê°’: gpt-4o)")
    github_group.add_argument("--generate-github-copilot-token", action="store_true", help="GitHub OAuthë¥¼ í†µí•´ ìƒˆë¡œìš´ ì•¡ì„¸ìŠ¤ í† í°ì„ ìƒì„±í•©ë‹ˆë‹¤ (ëŒ€í™”í˜• ëª¨ë“œ)")

    parser.add_argument("--seed-glossary-file", type=Path, default=None, help="ìš©ì–´ì§‘ ìƒì„± ì‹œ ì°¸ê³ í•  ê¸°ì¡´ ìš©ì–´ì§‘ JSON íŒŒì¼ ê²½ë¡œ (ì„ íƒ ì‚¬í•­)")
    parser.add_argument("--extract_glossary_only", action="store_true", help="ë²ˆì—­ ëŒ€ì‹  ìš©ì–´ì§‘ ì¶”ì¶œë§Œ ìˆ˜í–‰í•©ë‹ˆë‹¤.") # ì¸ìˆ˜ëª… ë³€ê²½

    resume_group = parser.add_mutually_exclusive_group()
    resume_group.add_argument("--resume", action="store_true", help="ì´ì „ ë²ˆì—­ ì‘ì—…ì„ ì´ì–´ë°›ì•„ ê³„ì†í•©ë‹ˆë‹¤.")
    resume_group.add_argument("--force-new", action="store_true", help="ê¸°ì¡´ ì‘ì—… ë‚´ì—­ì„ ë¬´ì‹œí•˜ê³  ê°•ì œë¡œ ìƒˆë¡œ ë²ˆì—­ì„ ì‹œì‘í•©ë‹ˆë‹¤.")

    parser.add_argument("--log_level", choices=['DEBUG', 'INFO', 'WARNING', 'ERROR', 'CRITICAL'], default='INFO', help="ë¡œê·¸ ë ˆë²¨ ì„¤ì • (ê¸°ë³¸ê°’: INFO)")
    parser.add_argument("--log_file", type=Path, default=None, help="ë¡œê·¸ë¥¼ ì €ì¥í•  íŒŒì¼ ê²½ë¡œ (ê¸°ë³¸ê°’: btg_cli.log)")

    # ìš©ì–´ì§‘ ì¶”ì¶œ ë° ë²ˆì—­ ì‹œ ì†Œì„¤/ì¶œë°œ ì–¸ì–´ ì§€ì • (í†µí•©ë¨)
    parser.add_argument("--novel-language", type=str, default=None, help="ì†Œì„¤/ë²ˆì—­ ì¶œë°œ ì–¸ì–´ ì½”ë“œ (ì˜ˆ: ko, en, ja, auto). configì˜ novel_languageë¥¼ ë®ì–´ì”ë‹ˆë‹¤.")

    # ë™ì  ìš©ì–´ì§‘ ì£¼ì… ì„¤ì •
    dyn_glossary_group = parser.add_argument_group('ë™ì  ìš©ì–´ì§‘ ì£¼ì… ì„¤ì •') # Group name changed
    dyn_glossary_group.add_argument("--enable-dynamic-glossary-injection", action="store_true", help="ë™ì  ìš©ì–´ì§‘ ì£¼ì… ê¸°ëŠ¥ì„ í™œì„±í™”í•©ë‹ˆë‹¤.") # Arg name and help text changed
    dyn_glossary_group.add_argument("--max-glossary-entries-injection", type=int, help="ë²ˆì—­ ì²­í¬ë‹¹ ì£¼ì…í•  ìµœëŒ€ ìš©ì–´ì§‘ í•­ëª© ìˆ˜ (ì˜ˆ: 3)") # Arg name and help text changed
    dyn_glossary_group.add_argument("--max-glossary-chars-injection", type=int, help="ë²ˆì—­ ì²­í¬ë‹¹ ì£¼ì…í•  ìš©ì–´ì§‘ì˜ ìµœëŒ€ ì´ ë¬¸ì ìˆ˜ (ì˜ˆ: 500)") # Arg name and help text changed
    # ì„¤ì • ì˜¤ë²„ë¼ì´ë“œ
    config_override_group = parser.add_argument_group('Configuration Overrides')
    config_override_group.add_argument("--novel-language-override", type=str, help="ì„¤ì • íŒŒì¼ì˜ 'novel_language' ê°’ì„ ë®ì–´ì”ë‹ˆë‹¤. (--novel-languageì™€ ë™ì¼)")
    config_override_group.add_argument("--novel-language-fallback-override", type=str, help="ì„¤ì • íŒŒì¼ì˜ 'novel_language_fallback' ê°’ì„ ë®ì–´ì”ë‹ˆë‹¤.")
    config_override_group.add_argument("--rpm", type=int, help="ë¶„ë‹¹ API ìš”ì²­ ìˆ˜ë¥¼ ì„¤ì •í•©ë‹ˆë‹¤. (ì˜ˆ: 60). 0ì€ ì œí•œ ì—†ìŒì„ ì˜ë¯¸í•©ë‹ˆë‹¤.")
    config_override_group.add_argument("--user-override-glossary-prompt", type=str, help="ìš©ì–´ì§‘ ì¶”ì¶œ ì‹œ ì‚¬ìš©í•  ì‚¬ìš©ì ì •ì˜ í”„ë¡¬í”„íŠ¸ë¥¼ ì„¤ì •í•©ë‹ˆë‹¤.")
    return parser.parse_args()

def generate_github_copilot_token():
    """CLIì—ì„œ GitHub Copilot í† í°ì„ ìƒì„±í•©ë‹ˆë‹¤."""
    import webbrowser
    import time
    
    print("\n=== GitHub Copilot í† í° ìƒì„± ===")
    print("GitHub OAuth ë””ë°”ì´ìŠ¤ í”Œë¡œìš°ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤...")
    
    github_auth = GitHubAuthService()
    
    try:
        # 1. ë””ë°”ì´ìŠ¤ ì½”ë“œ ìš”ì²­
        print("GitHubì—ì„œ ë””ë°”ì´ìŠ¤ ì½”ë“œë¥¼ ìš”ì²­í•˜ëŠ” ì¤‘...")
        device_code_response = github_auth.request_device_code()
        
        user_code = device_code_response["user_code"]
        verification_uri = device_code_response["verification_uri"]
        device_code = device_code_response["device_code"]
        expires_in = device_code_response["expires_in"]
        interval = device_code_response.get("interval", 5)
        
        print(f"\nğŸ“± ì¸ì¦ ë‹¨ê³„:")
        print(f"1. ë¸Œë¼ìš°ì €ì—ì„œ {verification_uri} ë¡œ ì´ë™í•©ë‹ˆë‹¤")
        print(f"2. ë‹¤ìŒ ì½”ë“œë¥¼ ì…ë ¥í•˜ì„¸ìš”: {user_code}")
        print(f"3. GitHub ê³„ì •ìœ¼ë¡œ ë¡œê·¸ì¸í•˜ê³  ê¶Œí•œì„ ìŠ¹ì¸í•˜ì„¸ìš”")
        print(f"4. ì´ í”„ë¡œê·¸ë¨ì€ ìë™ìœ¼ë¡œ í† í°ì„ í™•ì¸í•©ë‹ˆë‹¤ (ìµœëŒ€ {expires_in//60}ë¶„)")
        
        # 2. ë¸Œë¼ìš°ì € ìë™ ì—´ê¸°
        try:
            webbrowser.open(verification_uri)
            print(f"\nâœ… ë¸Œë¼ìš°ì €ì—ì„œ {verification_uri} í˜ì´ì§€ë¥¼ ì—´ì—ˆìŠµë‹ˆë‹¤.")
        except Exception as e:
            print(f"âš ï¸ ë¸Œë¼ìš°ì € ìë™ ì—´ê¸° ì‹¤íŒ¨: {e}")
            print(f"ìˆ˜ë™ìœ¼ë¡œ {verification_uri} ë¥¼ ì—´ì–´ì£¼ì„¸ìš”.")
        
        print(f"\nâ³ ì¸ì¦ ì™„ë£Œë¥¼ ê¸°ë‹¤ë¦¬ëŠ” ì¤‘... (ì½”ë“œ: {user_code})")
        
        # 3. í† í° í´ë§
        max_attempts = expires_in // interval
        for attempt in range(max_attempts):
            try:
                time.sleep(interval)
                print(".", end="", flush=True)
                
                access_token = github_auth.poll_for_token(device_code)
                if access_token:
                    print(f"\n\nğŸ‰ GitHub Copilot í† í° ìƒì„± ì„±ê³µ!")
                    print(f"í† í°: {access_token[:20]}...")
                    
                    # 4. í† í° ê²€ì¦
                    print("í† í°ì„ ê²€ì¦í•˜ëŠ” ì¤‘...")
                    is_valid, user_info = github_auth.validate_token(access_token)
                    
                    if is_valid:
                        print(f"âœ… í† í° ê²€ì¦ ì„±ê³µ! GitHub ì‚¬ìš©ì: {user_info.get('login', 'Unknown')}")
                        
                        # 5. ì„¤ì •ì— ì €ì¥
                        config_manager = ConfigManager()
                        config = config_manager.load_config()
                        config["github_copilot_enabled"] = True
                        config["github_copilot_access_token"] = access_token
                        config_manager.save_config(config)
                        
                        print(f"âœ… í† í°ì´ ì„¤ì • íŒŒì¼ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
                        print(f"\nì´ì œ --use-github-copilot í”Œë˜ê·¸ë¡œ GitHub Copilotì„ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤!")
                        return access_token
                    else:
                        print(f"âŒ í† í° ê²€ì¦ ì‹¤íŒ¨: {user_info}")
                        return None
                        
            except Exception as e:
                if "authorization_pending" in str(e).lower():
                    continue  # ì•„ì§ ì‚¬ìš©ìê°€ ì¸ì¦í•˜ì§€ ì•ŠìŒ
                elif "slow_down" in str(e).lower():
                    time.sleep(interval)  # ìš”ì²­ ì†ë„ ì¡°ì ˆ
                    continue
                else:
                    print(f"\nâŒ í† í° í´ë§ ì¤‘ ì˜¤ë¥˜: {e}")
                    return None
        
        print(f"\nâ° ì‹œê°„ ì´ˆê³¼: {expires_in//60}ë¶„ ë‚´ì— ì¸ì¦ì´ ì™„ë£Œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        print("ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")
        return None
        
    except Exception as e:
        print(f"âŒ GitHub í† í° ìƒì„± ì‹¤íŒ¨: {e}")
        return None

def generate_github_copilot_token_interactive(config_file_path: Path) -> Optional[str]:
    """
    CLIì—ì„œ GitHub Copilot í† í°ì„ ëŒ€í™”ì‹ìœ¼ë¡œ ìƒì„±í•˜ê³  ì„¤ì • íŒŒì¼ì— ì €ì¥í•©ë‹ˆë‹¤.
    
    Args:
        config_file_path: ì„¤ì • íŒŒì¼ ê²½ë¡œ
        
    Returns:
        ìƒì„±ëœ í† í° ë¬¸ìì—´ ë˜ëŠ” None
    """
    try:
        print("\nğŸš€ GitHub Copilot í† í° ìƒì„±ì„ ì‹œì‘í•©ë‹ˆë‹¤...")
        
        # ConfigManager ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
        config_manager = ConfigManager(config_file_path)
        
        # GitHub OAuth ì„œë¹„ìŠ¤ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
        github_auth = GitHubAuthService(config_manager)
        
        # Device flow ì‹œì‘
        device_response = github_auth.get_device_code()
        
        print(f"\nğŸ”— ë‹¤ìŒ URLì„ ë¸Œë¼ìš°ì €ì—ì„œ ì—´ì–´ì£¼ì„¸ìš”:")
        print(f"   {device_response.verification_uri}")
        print(f"\nğŸ”‘ ë‹¤ìŒ ì½”ë“œë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”:")
        print(f"   {device_response.user_code}")
        print(f"\nâ±ï¸  {device_response.expires_in // 60}ë¶„ ë‚´ì— ì¸ì¦ì„ ì™„ë£Œí•´ì£¼ì„¸ìš”...")
        print("   Enter í‚¤ë¥¼ ëˆŒëŸ¬ì„œ í† í° í™•ì¸ì„ ì‹œì‘í•˜ê±°ë‚˜, Ctrl+Cë¡œ ì·¨ì†Œí•˜ì„¸ìš”.")
        
        try:
            input()  # ì‚¬ìš©ìê°€ Enterë¥¼ ëˆ„ë¥¼ ë•Œê¹Œì§€ ëŒ€ê¸°
        except KeyboardInterrupt:
            print("\nâŒ ì‚¬ìš©ìê°€ ì·¨ì†Œí–ˆìŠµë‹ˆë‹¤.")
            return None
        
        # í† í° í´ë§ ì‹œì‘
        print("\nğŸ”„ í† í° í™•ì¸ ì¤‘...")
        token_response = github_auth.poll_for_access_token(
            device_response.device_code,
            device_response.interval,
            device_response.expires_in
        )
        
        if token_response and token_response.access_token:
            # í† í° ê²€ì¦
            if github_auth.verify_token(token_response.access_token):
                # í† í°ì„ ì„¤ì •ì— ì €ì¥
                if github_auth.save_access_token(token_response.access_token):
                    print(f"\nâœ… GitHub Copilot í† í°ì´ ì„±ê³µì ìœ¼ë¡œ ìƒì„±ë˜ê³  ì„¤ì • íŒŒì¼ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤!")
                    print(f"   ì„¤ì • íŒŒì¼: {config_file_path}")
                    return token_response.access_token
                else:
                    print(f"\nâŒ í† í° ì €ì¥ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
                    return None
            else:
                print(f"\nâŒ í† í° ê²€ì¦ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
                return None
        else:
            print(f"\nâŒ í† í° ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
            return None
            
    except Exception as e:
        print(f"\nâŒ í† í° ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
        return None

def main():
    args = parse_arguments()

    log_file_path = args.log_file if args.log_file else Path("btg_cli.log")
    setup_logger(logger_name="btg_cli", log_level=getattr(logging, args.log_level.upper()), log_file=log_file_path)

    cli_logger.info("BTG CLI ì‹œì‘...")
    cli_logger.info(f"ì…ë ¥ íŒŒì¼: {args.input_file}")
    cli_logger.info(f"ì„¤ì • íŒŒì¼: {args.config}")
    if args.resume: cli_logger.info("ì´ì–´í•˜ê¸° ì˜µì…˜ (--resume) í™œì„±í™”ë¨.")
    if args.force_new: cli_logger.info("ìƒˆë¡œ ì‹œì‘ ì˜µì…˜ (--force-new) í™œì„±í™”ë¨.")

    # GitHub Copilot í† í° ìƒì„± ì²˜ë¦¬ (ë‹¤ë¥¸ ì‘ì—…ë³´ë‹¤ ë¨¼ì € ì‹¤í–‰)
    if args.generate_github_copilot_token:
        cli_logger.info("GitHub Copilot í† í° ìƒì„± ìš”ì²­ë¨...")
        try:
            token = generate_github_copilot_token_interactive(args.config)
            if token:
                print(f"GitHub Copilot í† í°ì´ ì„±ê³µì ìœ¼ë¡œ ìƒì„±ë˜ê³  ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
                print(f"í† í°: {token}")
            else:
                print("í† í° ìƒì„±ì´ ì·¨ì†Œë˜ê±°ë‚˜ ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
                sys.exit(1)
        except Exception as e:
            cli_logger.error(f"GitHub Copilot í† í° ìƒì„± ì¤‘ ì˜¤ë¥˜: {e}")
            print(f"ì˜¤ë¥˜: {e}")
            sys.exit(1)
        return  # í† í° ìƒì„± í›„ ì¢…ë£Œ

    try:
        app_service = AppService(config_file_path=args.config)
        
        cli_overrides: Dict[str, Any] = {}
        config_changed_by_cli = False

        if args.api_keys:
            api_keys_list = [key.strip() for key in args.api_keys.split(',') if key.strip()]
            if api_keys_list:
                cli_overrides["api_keys"] = api_keys_list
                cli_overrides["api_key"] = api_keys_list[0]
                cli_overrides["use_vertex_ai"] = False
                cli_overrides["service_account_file_path"] = None
                cli_overrides["auth_credentials"] = None
                config_changed_by_cli = True
                cli_logger.info(f"--api-keysë¡œ {len(api_keys_list)}ê°œì˜ API í‚¤ê°€ ì„¤ì •ë˜ì—ˆìŠµë‹ˆë‹¤.")
            else:
                cli_logger.warning("--api-keys ì¸ìˆ˜ê°€ ì œê³µë˜ì—ˆì§€ë§Œ ìœ íš¨í•œ í‚¤ê°€ ì—†ìŠµë‹ˆë‹¤.")

        elif args.auth_credentials_file:
            cli_logger.info(f"ì„œë¹„ìŠ¤ ê³„ì • íŒŒì¼ì—ì„œ ì¸ì¦ ì •ë³´ ë¡œë“œ ì‹œë„: {args.auth_credentials_file}")
            if not args.auth_credentials_file.exists():
                cli_logger.error(f"ì„œë¹„ìŠ¤ ê³„ì • íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {args.auth_credentials_file}")
                sys.exit(1)
            try:
                cli_overrides["service_account_file_path"] = str(args.auth_credentials_file.resolve())
                cli_overrides["api_key"] = None
                cli_overrides["api_keys"] = []
                cli_overrides["auth_credentials"] = None
                cli_overrides["use_vertex_ai"] = True
                config_changed_by_cli = True
                cli_logger.info(f"ì„œë¹„ìŠ¤ ê³„ì • íŒŒì¼ ê²½ë¡œ '{args.auth_credentials_file}'ë¥¼ ì„¤ì •ì— ë°˜ì˜í–ˆìŠµë‹ˆë‹¤.")
            except Exception as e:
                cli_logger.error(f"ì„œë¹„ìŠ¤ ê³„ì • íŒŒì¼ ê²½ë¡œ ì„¤ì • ì¤‘ ì˜¤ë¥˜: {e}")
                sys.exit(1)
        elif args.auth_credentials:
            cli_overrides["auth_credentials"] = args.auth_credentials
            cli_overrides["api_key"] = None
            cli_overrides["api_keys"] = []
            cli_overrides["service_account_file_path"] = None
            config_changed_by_cli = True
            cli_logger.info("ëª…ë ¹ì¤„ --auth-credentials ì‚¬ìš©.")

        if args.use_vertex_ai and not args.api_keys: # --api-keysê°€ ìš°ì„ ìˆœìœ„ê°€ ë” ë†’ìŒ
            cli_overrides["use_vertex_ai"] = True
            cli_overrides["api_key"] = None
            cli_overrides["api_keys"] = []
            config_changed_by_cli = True
        if args.gcp_project:
            cli_overrides["gcp_project"] = args.gcp_project
            config_changed_by_cli = True
        if args.gcp_location:
            cli_overrides["gcp_location"] = args.gcp_location
            config_changed_by_cli = True
        
        # ë™ì  ë¡œì–´ë¶ ì£¼ì… ì„¤ì • CLI ì¸ì ì²˜ë¦¬
        if args.enable_dynamic_glossary_injection: # Arg name changed
            cli_overrides["enable_dynamic_glossary_injection"] = True # Key changed
            config_changed_by_cli = True
        if args.max_glossary_entries_injection is not None: # Arg name changed
            cli_overrides["max_glossary_entries_per_chunk_injection"] = args.max_glossary_entries_injection # Key changed
            config_changed_by_cli = True
        if args.max_glossary_chars_injection is not None: # Arg name changed
            cli_overrides["max_glossary_chars_per_chunk_injection"] = args.max_glossary_chars_injection # Key changed
            config_changed_by_cli = True

        # CLI ì¸ì --novel-languageì™€ --novel-language-override ë‘˜ ë‹¤ novel_language ì„¤ì •ì„ ë³€ê²½        # CLI ì¸ì --novel-languageì™€ --novel-language-override ë‘˜ ë‹¤ novel_language ì„¤ì •ì„ ë³€ê²½
        novel_lang_arg = args.novel_language or args.novel_language_override
        if novel_lang_arg:
            cli_overrides["novel_language"] = novel_lang_arg
            config_changed_by_cli = True
        if args.novel_language_fallback_override:
            cli_overrides["novel_language_fallback"] = args.novel_language_fallback_override
            config_changed_by_cli = True
        if args.rpm is not None:
            cli_overrides["requests_per_minute"] = args.rpm
            config_changed_by_cli = True
            cli_logger.info(f"ë¶„ë‹¹ ìš”ì²­ ìˆ˜(RPM)ê°€ CLI ì¸ìˆ˜ë¡œ ì¸í•´ '{args.rpm}' (ìœ¼)ë¡œ ì„¤ì •ë©ë‹ˆë‹¤.")
        if args.user_override_glossary_prompt:
            cli_overrides["user_override_glossary_extraction_prompt"] = args.user_override_glossary_prompt
            config_changed_by_cli = True
            cli_logger.info(f"ì‚¬ìš©ì ì¬ì •ì˜ ìš©ì–´ì§‘ ì¶”ì¶œ í”„ë¡¬í”„íŠ¸ê°€ CLI ì¸ìˆ˜ë¡œ ì„¤ì •ë˜ì—ˆìŠµë‹ˆë‹¤.")

        # GitHub Copilot ê´€ë ¨ CLI ì¸ìˆ˜ ì²˜ë¦¬
        if args.use_github_copilot:
            cli_overrides["github_copilot_enabled"] = True
            config_changed_by_cli = True
            cli_logger.info("--use-github-copilot í”Œë˜ê·¸ë¡œ GitHub Copilotì´ í™œì„±í™”ë˜ì—ˆìŠµë‹ˆë‹¤.")
            
        if args.github_copilot_token:
            cli_overrides["github_copilot_access_token"] = args.github_copilot_token
            config_changed_by_cli = True
            cli_logger.info("GitHub Copilot í† í°ì´ CLI ì¸ìˆ˜ë¡œ ì œê³µë˜ì—ˆìŠµë‹ˆë‹¤.")
            
        if args.github_copilot_model:
            cli_overrides["github_copilot_model"] = args.github_copilot_model
            config_changed_by_cli = True
            cli_logger.info(f"GitHub Copilot ëª¨ë¸ì´ CLI ì¸ìˆ˜ë¡œ '{args.github_copilot_model}'(ìœ¼)ë¡œ ì„¤ì •ë˜ì—ˆìŠµë‹ˆë‹¤.")

        if config_changed_by_cli:
            cli_logger.info("CLI ì¸ìˆ˜ë¡œ ì œê³µëœ ì„¤ì •ì„ ë°˜ì˜í•˜ê¸° ìœ„í•´ AppService ì„¤ì •ì„ ë‹¤ì‹œ ë¡œë“œí•©ë‹ˆë‹¤.")
            app_service.load_app_config(runtime_overrides=cli_overrides)

        if args.seed_glossary_file:
            cli_logger.info(f"ìš©ì–´ì§‘ ìƒì„± ì‹œ ì°¸ê³ í•  íŒŒì¼: {args.seed_glossary_file}")
            # seed_glossary_fileì€ extract_glossary í˜¸ì¶œ ì‹œ ì§ì ‘ ì „ë‹¬ë˜ë¯€ë¡œ,
            # configì— ì €ì¥í•˜ê³  load_app_configë¥¼ í†µí•´ ë³´ì¡´í•  í•„ìš”ëŠ” í˜„ì¬ ì—†ìŠµë‹ˆë‹¤.
            # ë§Œì•½ ì´ ê°’ë„ configì˜ ì¼ë¶€ë¡œ ê´€ë¦¬í•˜ê³  ì‹¶ë‹¤ë©´, cli_overridesì— ì¶”ê°€í•˜ê³ 
            # app_service.load_app_config(runtime_overrides=cli_overrides)ë¥¼ í˜¸ì¶œí•´ì•¼ í•©ë‹ˆë‹¤.
            # í˜„ì¬ëŠ” AppServiceì˜ configì— ì§ì ‘ ì˜í–¥ì„ ì£¼ì§€ ì•Šìœ¼ë¯€ë¡œ load_app_config í˜¸ì¶œ ë¶ˆí•„ìš”.
        
        # type: ignore
        if args.extract_glossary_only: # ì¸ìˆ˜ëª… ë³€ê²½
            cli_logger.info("ìš©ì–´ì§‘ ì¶”ì¶œ ëª¨ë“œë¡œ ì‹¤í–‰í•©ë‹ˆë‹¤.") # ë©”ì‹œì§€ ë³€ê²½
            if not args.input_file.exists():
                cli_logger.error(f"ì…ë ¥ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {args.input_file}")
                sys.exit(1)
        
            result_glossary_path = app_service.extract_glossary(
                args.input_file,
                progress_callback=cli_glossary_extraction_progress_callback, # ì½œë°± í•¨ìˆ˜ëª… ë³€ê²½
                novel_language_code=app_service.config.get("novel_language"),
                seed_glossary_path=args.seed_glossary_file,
                user_override_glossary_extraction_prompt=app_service.config.get("user_override_glossary_extraction_prompt")
            )
            Tqdm.write(f"\nìš©ì–´ì§‘ ì¶”ì¶œ ì™„ë£Œ. ê²°ê³¼ íŒŒì¼: {result_glossary_path}", file=sys.stdout) # ë©”ì‹œì§€ ë³€ê²½

        else: # ë²ˆì—­ ëª¨ë“œ
            output_file = args.output_file
            if not output_file:
                output_file = args.input_file.parent / f"{args.input_file.stem}_translated{args.input_file.suffix}"
            cli_logger.info(f"ì¶œë ¥ íŒŒì¼: {output_file}")

            if not args.input_file.exists():
                cli_logger.error(f"ì…ë ¥ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {args.input_file}")
                sys.exit(1)

            metadata_file_path = get_metadata_file_path(args.input_file)
            loaded_metadata = load_metadata(metadata_file_path)
            current_config_hash = _hash_config_for_metadata(app_service.config)
            previous_config_hash = loaded_metadata.get("config_hash")

            should_start_new = False

            if args.force_new:
                cli_logger.info("--force-new ì˜µì…˜ìœ¼ë¡œ ê°•ì œ ìƒˆë¡œ ë²ˆì—­ì„ ì‹œì‘í•©ë‹ˆë‹¤.")
                should_start_new = True
            elif args.resume:
                if previous_config_hash and previous_config_hash == current_config_hash:
                    cli_logger.info("--resume ì˜µì…˜ ë° ì„¤ì • ì¼ì¹˜ë¡œ ì´ì–´í•˜ê¸°ë¥¼ ì‹œë„í•©ë‹ˆë‹¤.")
                elif previous_config_hash:
                    cli_logger.warning("ì„¤ì •ì´ ì´ì „ ì‘ì—…ê³¼ ë‹¤ë¦…ë‹ˆë‹¤. --resume ì˜µì…˜ì´ ë¬´ì‹œë˜ê³  ìƒˆë¡œ ë²ˆì—­ì„ ì‹œì‘í•©ë‹ˆë‹¤.")
                    should_start_new = True
                else:
                    cli_logger.info("ì´ì „ ì‘ì—… ë‚´ì—­ì´ ì—†ìŠµë‹ˆë‹¤. ìƒˆë¡œ ë²ˆì—­ì„ ì‹œì‘í•©ë‹ˆë‹¤. (--resume ì˜µì…˜ ë¬´ì‹œ)")
                    should_start_new = True
            else:
                if previous_config_hash and previous_config_hash == current_config_hash:
                    Tqdm.write(
                        f"'{args.input_file.name}'ì— ëŒ€í•œ ì´ì „ ë²ˆì—­ ì‘ì—… ë‚´ì—­ì´ ìˆìŠµë‹ˆë‹¤.\n"
                        f"  ì´ì–´í•˜ë ¤ë©´: --resume\n"
                        f"  ìƒˆë¡œ ì‹œì‘í•˜ë ¤ë©´: --force-new\n"
                        "ì˜µì…˜ ì—†ì´ ì‹¤í–‰í•˜ë©´ ìƒˆë¡œ ë²ˆì—­ì„ ì‹œì‘í•©ë‹ˆë‹¤ (ê¸°ì¡´ ë‚´ì—­ ì‚­ì œ). ê³„ì†í•˜ì‹œê² ìŠµë‹ˆê¹Œ? [y/N]: ",
                        file=sys.stdout
                    )
                    try:
                        answer = input().lower()
                        if answer != 'y':
                            cli_logger.info("ì‚¬ìš©ì ì·¨ì†Œ.")
                            sys.exit(0)
                        cli_logger.info("ì‚¬ìš©ì ë™ì˜ í•˜ì— ìƒˆë¡œ ë²ˆì—­ì„ ì‹œì‘í•©ë‹ˆë‹¤.")
                        should_start_new = True
                    except Exception:
                        cli_logger.info("ì…ë ¥ ì˜¤ë¥˜ ë˜ëŠ” ì‹œê°„ ì´ˆê³¼ë¡œ í”„ë¡œê·¸ë¨ì„ ì¢…ë£Œí•©ë‹ˆë‹¤. ì˜µì…˜ì„ ëª…ì‹œí•˜ì—¬ ë‹¤ì‹œ ì‹¤í–‰í•´ì£¼ì„¸ìš”.")
                        sys.exit(0)


                elif previous_config_hash and previous_config_hash != current_config_hash:
                    cli_logger.info("ì„¤ì •ì´ ì´ì „ ì‘ì—…ê³¼ ë‹¤ë¦…ë‹ˆë‹¤. ìƒˆë¡œ ë²ˆì—­ì„ ì‹œì‘í•©ë‹ˆë‹¤.")
                    should_start_new = True
                else:
                    cli_logger.info("ì´ì „ ì‘ì—… ë‚´ì—­ì´ ì—†ìŠµë‹ˆë‹¤. ìƒˆë¡œ ë²ˆì—­ì„ ì‹œì‘í•©ë‹ˆë‹¤.")
                    should_start_new = True

            if should_start_new:
                cli_logger.info("ìƒˆë¡œ ë²ˆì—­ì„ ìœ„í•´ ê¸°ì¡´ ë©”íƒ€ë°ì´í„° ë° ì¶œë ¥ íŒŒì¼ì„ ì‚­ì œí•©ë‹ˆë‹¤.")
                if metadata_file_path.exists(): delete_file(metadata_file_path)
                if output_file.exists(): delete_file(output_file)

            cli_logger.info("ë²ˆì—­ ëª¨ë“œë¡œ ì‹¤í–‰í•©ë‹ˆë‹¤.")
            app_service.start_translation(
                args.input_file,
                output_file,
                progress_callback=cli_translation_progress_callback,
                status_callback=cli_translation_status_callback,
                tqdm_file_stream=sys.stdout
            )
            Tqdm.write(f"\në²ˆì—­ ì‘ì—… ì™„ë£Œ. ê²°ê³¼ íŒŒì¼: {output_file}", file=sys.stdout)

    except BtgException as e:
        cli_logger.error(f"BTG ì• í”Œë¦¬ì¼€ì´ì…˜ ì˜¤ë¥˜: {e}", exc_info=True)
        Tqdm.write(f"\nì˜¤ë¥˜ ë°œìƒ: {e}", file=sys.stderr)
        sys.exit(1)
    except Exception as e:
        cli_logger.error(f"ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜ ë°œìƒ: {e}", exc_info=True)
        Tqdm.write(f"\nì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜: {e}", file=sys.stderr)
        sys.exit(1)
    finally:
        with tqdm_lock:
            for task_id in list(tqdm_instances.keys()):
                if tqdm_instances[task_id]:
                    tqdm_instances[task_id].close() # type: ignore
                del tqdm_instances[task_id] # type: ignore
        cli_logger.info("BTG CLI ì¢…ë£Œ.")

if __name__ == "__main__":
    main()
