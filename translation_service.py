# translation_service.py
import time
import random
import re
import csv
from pathlib import Path
from typing import Dict, Any, Optional, List, Union
import os

try:
    from .gemini_client import (
        GeminiClient,
        GeminiContentSafetyException,
        GeminiRateLimitException,
        GeminiApiException,
        GeminiInvalidRequestException,
        GeminiAllApiKeysExhaustedException 
    )
    from .file_handler import read_json_file # JSON ë¡œë”©ì„ ìœ„í•´ ì¶”ê°€
    from .logger_config import setup_logger
    from .exceptions import BtgTranslationException, BtgApiClientException
    from .chunk_service import ChunkService
    # types ëª¨ë“ˆì€ gemini_clientì—ì„œ ì‚¬ìš©ë˜ë¯€ë¡œ, ì—¬ê¸°ì„œëŠ” ì§ì ‘ì ì¸ ì˜ì¡´ì„±ì´ ì—†ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
    # ë§Œì•½ ì´ íŒŒì¼ ë‚´ì—ì„œ types.Part ë“±ì„ ì§ì ‘ ì‚¬ìš©í•œë‹¤ë©´, ì•„ë˜ì™€ ê°™ì´ ì„í¬íŠ¸ê°€ í•„ìš”í•©ë‹ˆë‹¤.
    # from google.genai import types as genai_types 
    from .dtos import LorebookEntryDTO # ë¡œì–´ë¶ DTO ì„í¬íŠ¸
except ImportError:
    from gemini_client import (
        GeminiClient,
        GeminiContentSafetyException,
        GeminiRateLimitException,
        GeminiApiException,
        GeminiInvalidRequestException,
        GeminiAllApiKeysExhaustedException 
    )
    from file_handler import read_json_file # JSON ë¡œë”©ì„ ìœ„í•´ ì¶”ê°€
    from logger_config import setup_logger
    from exceptions import BtgTranslationException, BtgApiClientException
    from chunk_service import ChunkService
    from dtos import LorebookEntryDTO # ë¡œì–´ë¶ DTO ì„í¬íŠ¸
    # from google.genai import types as genai_types # Fallback import

logger = setup_logger(__name__)

def _format_lorebook_for_prompt(
    lorebook_entries: List[LorebookEntryDTO],
    max_entries: int,
    max_chars: int
) -> str:
    if not lorebook_entries:
        return "ë¡œì–´ë¶ ì»¨í…ìŠ¤íŠ¸ ì—†ìŒ"

    selected_entries_str = []
    current_chars = 0
    entries_count = 0

    # ì¤‘ìš”ë„ ë†’ì€ ìˆœ, ì¤‘ìš”ë„ ê°™ìœ¼ë©´ í‚¤ì›Œë“œ ê°€ë‚˜ë‹¤ ìˆœìœ¼ë¡œ ì •ë ¬
    # isSpoilerê°€ Trueì¸ í•­ëª©ì€ ë‚®ì€ ìš°ì„ ìˆœìœ„ë¥¼ ê°–ë„ë¡ ì¡°ì • (ì˜ˆ: ì¤‘ìš”ë„ë¥¼ ë‚®ì¶¤)
    def sort_key(entry: LorebookEntryDTO):
        importance = entry.importance or 0
        if entry.isSpoiler:
            importance -= 100 # ìŠ¤í¬ì¼ëŸ¬ í•­ëª©ì˜ ì¤‘ìš”ë„ë¥¼ í¬ê²Œ ë‚®ì¶¤
        return (-importance, entry.keyword.lower())

    sorted_entries = sorted(lorebook_entries, key=sort_key)

    for entry in sorted_entries:
        if entries_count >= max_entries:
            break

        spoiler_text = "ì˜ˆ" if entry.isSpoiler else "ì•„ë‹ˆì˜¤"
        details_parts = []
        if entry.category:
            details_parts.append(f"ì¹´í…Œê³ ë¦¬: {entry.category}")
        details_parts.append(f"ìŠ¤í¬ì¼ëŸ¬: {spoiler_text}")
        
        details_str = ", ".join(details_parts)
        entry_str = f"- {entry.keyword}: {entry.description} ({details_str})"
        
        # í˜„ì¬ í•­ëª© ì¶”ê°€ ì‹œ ìµœëŒ€ ê¸€ì ìˆ˜ ì´ˆê³¼í•˜ë©´ ì¤‘ë‹¨ (ë‹¨, ìµœì†Œ 1ê°œëŠ” í¬í•¨ë˜ë„ë¡)
        if current_chars + len(entry_str) > max_chars and entries_count > 0:
            break
        
        selected_entries_str.append(entry_str)
        current_chars += len(entry_str) + 1 # +1 for newline
        entries_count += 1
    
    if not selected_entries_str:
        return "ë¡œì–´ë¶ ì»¨í…ìŠ¤íŠ¸ ì—†ìŒ (ì œí•œìœ¼ë¡œ ì¸í•´ ì„ íƒëœ í•­ëª© ì—†ìŒ)"
        
    return "\n".join(selected_entries_str)

class TranslationService:
    def __init__(self, gemini_client: GeminiClient, config: Dict[str, Any]):
        self.gemini_client = gemini_client
        self.config = config
        self.chunk_service = ChunkService()
        self.lorebook_entries_for_injection: List[LorebookEntryDTO] = [] # For new lorebook injection

        if self.config.get("enable_dynamic_lorebook_injection", False):
            self._load_lorebook_data()
            logger.info("ë™ì  ë¡œì–´ë¶ ì£¼ì… í™œì„±í™”ë¨. ë¡œì–´ë¶ ë°ì´í„° ë¡œë“œ ì‹œë„.")
        else:
            logger.info("ë™ì  ë¡œì–´ë¶ ì£¼ì… ë¹„í™œì„±í™”ë¨. ë¡œì–´ë¶ ì»¨í…ìŠ¤íŠ¸ ì—†ì´ ë²ˆì—­í•©ë‹ˆë‹¤.")

    def _load_lorebook_data(self):
        lorebook_json_path_str = self.config.get("lorebook_json_path_for_injection")
        if lorebook_json_path_str and os.path.exists(lorebook_json_path_str):
            lorebook_json_path = Path(lorebook_json_path_str)
            try:
                raw_data = read_json_file(lorebook_json_path)
                if isinstance(raw_data, list):
                    for item_dict in raw_data:
                        if isinstance(item_dict, dict) and "keyword" in item_dict and "description" in item_dict:
                            try:
                                entry = LorebookEntryDTO(
                                    keyword=item_dict.get("keyword", ""),
                                    description=item_dict.get("description", ""),
                                    category=item_dict.get("category"),
                                    importance=int(item_dict.get("importance", 0)) if item_dict.get("importance") is not None else None,
                                    sourceSegmentTextPreview=item_dict.get("sourceSegmentTextPreview"),
                                    isSpoiler=bool(item_dict.get("isSpoiler", False)),
                                    source_language=item_dict.get("source_language") # ë¡œì–´ë¶ JSONì—ì„œ source_language ë¡œë“œ
                                )
                                if entry.keyword and entry.description: # í•„ìˆ˜ í•„ë“œ í™•ì¸
                                    self.lorebook_entries_for_injection.append(entry)
                                else:
                                    logger.warning(f"ë¡œì–´ë¶ í•­ëª©ì— í•„ìˆ˜ í•„ë“œ(keyword ë˜ëŠ” description) ëˆ„ë½: {item_dict}")
                            except (TypeError, ValueError) as e_dto:
                                logger.warning(f"ë¡œì–´ë¶ í•­ëª© DTO ë³€í™˜ ì¤‘ ì˜¤ë¥˜: {item_dict}, ì˜¤ë¥˜: {e_dto}")
                        else:
                            logger.warning(f"ì˜ëª»ëœ ë¡œì–´ë¶ í•­ëª© í˜•ì‹ (ë”•ì…”ë„ˆë¦¬ê°€ ì•„ë‹ˆê±°ë‚˜ í•„ìˆ˜ í‚¤ ëˆ„ë½): {item_dict}")
                    logger.info(f"{len(self.lorebook_entries_for_injection)}ê°œì˜ ë¡œì–´ë¶ í•­ëª©ì„ ë¡œë“œí–ˆìŠµë‹ˆë‹¤: {lorebook_json_path}")
                else:
                    logger.error(f"ë¡œì–´ë¶ JSON íŒŒì¼ì´ ë¦¬ìŠ¤íŠ¸ í˜•ì‹ì´ ì•„ë‹™ë‹ˆë‹¤: {lorebook_json_path}, íƒ€ì…: {type(raw_data)}")
            except Exception as e:
                logger.error(f"ë¡œì–´ë¶ JSON íŒŒì¼ ì²˜ë¦¬ ì¤‘ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜ ({lorebook_json_path}): {e}", exc_info=True)
                self.lorebook_entries_for_injection = []
        else:
            logger.info("ë™ì  ì£¼ì…ìš© ë¡œì–´ë¶ JSON íŒŒì¼ì´ ì„¤ì •ë˜ì§€ ì•Šì•˜ê±°ë‚˜ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
            self.lorebook_entries_for_injection = []

    def _construct_prompt(self, chunk_text: str) -> str:
        prompt_template = self.config.get("prompts", "Translate to Korean: {{slot}}")
        if isinstance(prompt_template, (list, tuple)):
            prompt_template = prompt_template[0] if prompt_template else "Translate to Korean: {{slot}}"

        final_prompt = prompt_template

        # Determine the source language for the current chunk to filter lorebook entries
        config_source_lang = self.config.get("source_language_for_translation")
        # Fallback language from config, with a hardcoded default if the config key itself is missing
        config_fallback_lang = self.config.get("source_language_for_translation_fallback", "ja") 

        current_source_lang_for_translation: str # Type hint for clarity

        if config_source_lang == "auto":
            if chunk_text and chunk_text.strip():
                logger.info(f"ë²ˆì—­ ì¶œë°œ ì–¸ì–´ ìë™ ê°ì§€ ì‹œë„ (ì„¤ì •: 'auto', ì²­í¬ ì¼ë¶€: '{chunk_text[:30].strip()}...')...")
                try:
                    detected_lang = self.gemini_client.detect_language(chunk_text)
                    if detected_lang:
                        current_source_lang_for_translation = detected_lang
                        logger.info(f"ì²­í¬ ì–¸ì–´ ìë™ ê°ì§€ ì„±ê³µ: '{current_source_lang_for_translation}'")
                    else:
                        current_source_lang_for_translation = config_fallback_lang
                        logger.warning(f"ì²­í¬ ì–¸ì–´ ìë™ ê°ì§€ ì‹¤íŒ¨ (APIê°€ None ë°˜í™˜). í´ë°± ì–¸ì–´ '{current_source_lang_for_translation}' ì‚¬ìš©.")
                except Exception as e_detect:
                    current_source_lang_for_translation = config_fallback_lang
                    logger.error(f"ì²­í¬ ì–¸ì–´ ìë™ ê°ì§€ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e_detect}. í´ë°± ì–¸ì–´ '{current_source_lang_for_translation}' ì‚¬ìš©.")
            else:
                current_source_lang_for_translation = config_fallback_lang
                logger.info(f"ì²­í¬ í…ìŠ¤íŠ¸ê°€ ë¹„ì–´ìˆì–´ ì–¸ì–´ ìë™ ê°ì§€ë¥¼ ê±´ë„ˆë›°ê³  í´ë°± ì–¸ì–´ '{current_source_lang_for_translation}' ì‚¬ìš©.")
        elif config_source_lang and isinstance(config_source_lang, str) and config_source_lang.strip(): # Specific language code provided
            current_source_lang_for_translation = config_source_lang
            logger.info(f"ëª…ì‹œì  ë²ˆì—­ ì¶œë°œ ì–¸ì–´ '{current_source_lang_for_translation}' ì‚¬ìš©.")
        else: # config_source_lang is None, empty string, or not "auto"
            current_source_lang_for_translation = config_fallback_lang
            logger.warning(f"ë²ˆì—­ ì¶œë°œ ì–¸ì–´ê°€ ìœ íš¨í•˜ê²Œ ì„¤ì •ë˜ì§€ ì•Šì•˜ê±°ë‚˜ 'auto'ê°€ ì•„ë‹™ë‹ˆë‹¤. í´ë°± ì–¸ì–´ '{current_source_lang_for_translation}' ì‚¬ìš©.")

        # 1. Dynamic Lorebook Injection
        if self.config.get("enable_dynamic_lorebook_injection", False) and \
           self.lorebook_entries_for_injection and \
           "{{lorebook_context}}" in final_prompt:

            logger.debug(f"ë²ˆì—­ í”„ë¡¬í”„íŠ¸ êµ¬ì„± ì¤‘: ë²ˆì—­ ì¶œë°œ ì–¸ì–´ë¡œ '{current_source_lang_for_translation}' ì‚¬ìš©.")
            # 1.a. Filter lorebook entries relevant to the current chunk_text
            relevant_entries_for_chunk: List[LorebookEntryDTO] = []
            chunk_text_lower = chunk_text.lower() # For case-insensitive keyword matching
            for entry in self.lorebook_entries_for_injection:
                # ë¡œì–´ë¶ í•­ëª©ì˜ ì–¸ì–´ì™€ í˜„ì¬ ë²ˆì—­ ì¶œë°œ ì–¸ì–´ê°€ ì¼ì¹˜í•˜ëŠ”ì§€ í™•ì¸
                if entry.source_language and \
                   current_source_lang_for_translation and \
                   entry.source_language.lower() != current_source_lang_for_translation.lower():
                    logger.debug(f"ë¡œì–´ë¶ í•­ëª© '{entry.keyword}' ê±´ë„ˆëœ€: ì–¸ì–´ ë¶ˆì¼ì¹˜ (ë¡œì–´ë¶: {entry.source_language}, ë²ˆì—­ ì¶œë°œ: {current_source_lang_for_translation}).")
                    continue

                if entry.keyword.lower() in chunk_text_lower: # ì¤‘ìš”: ë¡œì–´ë¶ í‚¤ì›Œë“œëŠ” ë²ˆì—­ ì¶œë°œ ì–¸ì–´ì™€ ì¼ì¹˜í•´ì•¼ í•¨
                    relevant_entries_for_chunk.append(entry)
            
            logger.debug(f"í˜„ì¬ ì²­í¬ì— ëŒ€í•´ {len(relevant_entries_for_chunk)}ê°œì˜ ê´€ë ¨ ë¡œì–´ë¶ í•­ëª© ë°œê²¬.")

            # 1.b. Format the relevant entries for the prompt
            max_entries = self.config.get("max_lorebook_entries_per_chunk_injection", 3)
            max_chars = self.config.get("max_lorebook_chars_per_chunk_injection", 500)
            
            formatted_lorebook_context = _format_lorebook_for_prompt(
                relevant_entries_for_chunk, max_entries, max_chars # Pass only relevant entries
            )
            
            # Check if actual content was formatted (not just "ì—†ìŒ" messages)
            if formatted_lorebook_context != "ë¡œì–´ë¶ ì»¨í…ìŠ¤íŠ¸ ì—†ìŒ" and \
               formatted_lorebook_context != "ë¡œì–´ë¶ ì»¨í…ìŠ¤íŠ¸ ì—†ìŒ (ì œí•œìœ¼ë¡œ ì¸í•´ ì„ íƒëœ í•­ëª© ì—†ìŒ)":
                logger.info(f"API ìš”ì²­ì— ë™ì  ë¡œì–´ë¶ ì»¨í…ìŠ¤íŠ¸ ì£¼ì…ë¨. ë‚´ìš© ì¼ë¶€: {formatted_lorebook_context[:100]}...")
            else:
                logger.debug(f"ë™ì  ë¡œì–´ë¶ ì£¼ì… ì‹œë„í–ˆìœ¼ë‚˜, ê´€ë ¨ í•­ëª© ì—†ê±°ë‚˜ ì œí•œìœ¼ë¡œ ì¸í•´ ì‹¤ì œ ì£¼ì… ë‚´ìš© ì—†ìŒ. ì‚¬ìš©ëœ ë©”ì‹œì§€: {formatted_lorebook_context}")
            final_prompt = final_prompt.replace("{{lorebook_context}}", formatted_lorebook_context)
        else:
            if "{{lorebook_context}}" in final_prompt:
                 final_prompt = final_prompt.replace("{{lorebook_context}}", "ë¡œì–´ë¶ ì»¨í…ìŠ¤íŠ¸ ì—†ìŒ (ì£¼ì… ë¹„í™œì„±í™” ë˜ëŠ” í•´ë‹¹ í•­ëª© ì—†ìŒ)")
                 logger.debug("ë™ì  ë¡œì–´ë¶ ì£¼ì… ë¹„í™œì„±í™” ë˜ëŠ” í”Œë ˆì´ìŠ¤í™€ë” ë¶€ì¬ë¡œ 'ì»¨í…ìŠ¤íŠ¸ ì—†ìŒ' ë©”ì‹œì§€ ì‚¬ìš©.")
        
        # 3. Main content slot - This should be done *after* all other placeholders are processed.
        final_prompt = final_prompt.replace("{{slot}}", chunk_text)
        
        return final_prompt

    def translate_text(self, text_chunk: str) -> str:
        """ê¸°ì¡´ translate_text ë©”ì„œë“œ (ìˆ˜ì • ì—†ìŒ)"""
        if not text_chunk.strip():
            return ""

        processed_text = text_chunk
        prompt = self._construct_prompt(processed_text)

        try:
            logger.debug(f"Gemini API í˜¸ì¶œ ì‹œì‘. ëª¨ë¸: {self.config.get('model_name')}")
            
            translated_text = self.gemini_client.generate_text(
                prompt=prompt,
                model_name=self.config.get("model_name", "gemini-1.5-flash-latest"),
                generation_config_dict={
                    "temperature": self.config.get("temperature", 0.7),
                    "top_p": self.config.get("top_p", 0.9)
                },
            )

            if translated_text is None:
                logger.error("GeminiClient.generate_textê°€ Noneì„ ë°˜í™˜í–ˆìŠµë‹ˆë‹¤.")
                raise BtgApiClientException("API í˜¸ì¶œ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")

            logger.debug(f"Gemini API í˜¸ì¶œ ì„±ê³µ. ë²ˆì—­ëœ í…ìŠ¤íŠ¸ (ì¼ë¶€): {translated_text[:100]}...")

        except GeminiContentSafetyException as e_safety:
            logger.warning(f"ì½˜í…ì¸  ì•ˆì „ ë¬¸ì œë¡œ ë²ˆì—­ ì‹¤íŒ¨: {e_safety}")
            raise BtgTranslationException(f"ì½˜í…ì¸  ì•ˆì „ ë¬¸ì œë¡œ ë²ˆì—­í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ({e_safety})", original_exception=e_safety) from e_safety
        except GeminiAllApiKeysExhaustedException as e_keys:
            logger.error(f"API í‚¤ íšŒì „ ì‹¤íŒ¨: ëª¨ë“  API í‚¤ ì†Œì§„ ë˜ëŠ” ìœ íš¨í•˜ì§€ ì•ŠìŒ. ì›ë³¸ ì˜¤ë¥˜: {e_keys}")
            raise BtgApiClientException(f"ëª¨ë“  API í‚¤ë¥¼ ì‚¬ìš©í–ˆìœ¼ë‚˜ ìš”ì²­ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. API í‚¤ ì„¤ì •ì„ í™•ì¸í•˜ì„¸ìš”. ({e_keys})", original_exception=e_keys) from e_keys
        except GeminiRateLimitException as e_rate:
            logger.error(f"API ì‚¬ìš©ëŸ‰ ì œí•œ ì´ˆê³¼ (í‚¤ íšŒì „ í›„ì—ë„ ë°œìƒ): {e_rate}")
            raise BtgApiClientException(f"API ì‚¬ìš©ëŸ‰ ì œí•œì„ ì´ˆê³¼í–ˆìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”. ({e_rate})", original_exception=e_rate) from e_rate
        except GeminiInvalidRequestException as e_invalid:
            logger.error(f"ì˜ëª»ëœ API ìš”ì²­: {e_invalid}")
            raise BtgApiClientException(f"ì˜ëª»ëœ API ìš”ì²­ì…ë‹ˆë‹¤: {e_invalid}", original_exception=e_invalid) from e_invalid
        # ì¤‘ë³µëœ GeminiContentSafetyException ì œê±°
        except GeminiApiException as e_api:
            logger.error(f"Gemini API í˜¸ì¶œ ì¤‘ ì¼ë°˜ ì˜¤ë¥˜ ë°œìƒ: {e_api}")
            raise BtgApiClientException(f"API í˜¸ì¶œ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e_api}", original_exception=e_api) from e_api
        except Exception as e:
            logger.error(f"ë²ˆì—­ ì¤‘ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜ ë°œìƒ: {e}", exc_info=True)
            raise BtgTranslationException(f"ë²ˆì—­ ì¤‘ ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}", original_exception=e) from e
        
        final_text = translated_text 
        return final_text.strip()
    
    def translate_text_with_content_safety_retry(
        self, 
        text_chunk: str, 
        max_split_attempts: int = 3,
        min_chunk_size: int = 100
    ) -> str:
        """
        ì½˜í…ì¸  ì•ˆì „ ì˜¤ë¥˜ ë°œìƒì‹œ ì²­í¬ë¥¼ ë¶„í• í•˜ì—¬ ì¬ì‹œë„í•˜ëŠ” ë²ˆì—­ ë©”ì„œë“œ
        
        Args:
            text_chunk: ë²ˆì—­í•  í…ìŠ¤íŠ¸
            max_split_attempts: ìµœëŒ€ ë¶„í•  ì‹œë„ íšŸìˆ˜
            min_chunk_size: ìµœì†Œ ì²­í¬ í¬ê¸°
            
        Returns:
            ë²ˆì—­ëœ í…ìŠ¤íŠ¸ (ì‹¤íŒ¨í•œ ë¶€ë¶„ì€ ì˜¤ë¥˜ ë©”ì‹œì§€ë¡œ ëŒ€ì²´)
        """
        try:
            # 1ì°¨ ì‹œë„: ì „ì²´ ì²­í¬ ë²ˆì—­
            return self.translate_text(text_chunk)
            
        except BtgTranslationException as e:
            # ê²€ì—´ ì˜¤ë¥˜ê°€ ì•„ë‹Œ ê²½ìš° ê·¸ëŒ€ë¡œ ì˜ˆì™¸ ë°œìƒ
            if "ì½˜í…ì¸  ì•ˆì „ ë¬¸ì œ" not in str(e):
                raise e
            
            logger.warning(f"ì½˜í…ì¸  ì•ˆì „ ë¬¸ì œ ê°ì§€. ì²­í¬ ë¶„í•  ì¬ì‹œë„ ì‹œì‘: {str(e)}")
            return self._translate_with_recursive_splitting(
                text_chunk, max_split_attempts, min_chunk_size, current_attempt=1
            )

    def _translate_with_recursive_splitting(
        self,
        text_chunk: str,
        max_split_attempts: int,
        min_chunk_size: int,
        current_attempt: int = 1
    ) -> str:
    
        if current_attempt > max_split_attempts:
            logger.error(f"ìµœëŒ€ ë¶„í•  ì‹œë„ íšŸìˆ˜({max_split_attempts})ì— ë„ë‹¬. ë²ˆì—­ ì‹¤íŒ¨.")
            return f"[ê²€ì—´ë¡œ ì¸í•œ ë²ˆì—­ ì‹¤íŒ¨: ìµœëŒ€ ë¶„í•  ì‹œë„ ì´ˆê³¼]"

        if len(text_chunk.strip()) <= min_chunk_size:
            logger.warning(f"ìµœì†Œ ì²­í¬ í¬ê¸°ì— ë„ë‹¬í–ˆì§€ë§Œ ì—¬ì „íˆ ê²€ì—´ë¨: {text_chunk[:50]}...")
            return f"[ê²€ì—´ë¡œ ì¸í•œ ë²ˆì—­ ì‹¤íŒ¨: {text_chunk[:30]}...]"

        logger.info(f"ğŸ“Š ì²­í¬ ë¶„í•  ì‹œë„ #{current_attempt} (ê¹Šì´: {current_attempt-1})")
        logger.info(f"   ğŸ“ ì›ë³¸ í¬ê¸°: {len(text_chunk)} ê¸€ì")
        logger.info(f"   ğŸ¯ ëª©í‘œ í¬ê¸°: {len(text_chunk) // 2} ê¸€ì")
        logger.info(f"   ğŸ“ ë‚´ìš© ë¯¸ë¦¬ë³´ê¸°: {text_chunk[:100].replace(chr(10), ' ')}...")

        
        # 1ë‹¨ê³„: í¬ê¸° ê¸°ë°˜ ë¶„í• 
        sub_chunks = self.chunk_service.split_chunk_recursively(
            text_chunk,
            target_size=len(text_chunk) // 2,
            min_chunk_size=min_chunk_size,
            max_split_depth=1,  # 1ë‹¨ê³„ë§Œ ë¶„í• 
            current_depth=0
        )
        
        # ë¶„í• ì´ ì•ˆëœ ê²½ìš° ë¬¸ì¥ ê¸°ë°˜ ë¶„í•  ì‹œë„
        if len(sub_chunks) <= 1:
            logger.info("í¬ê¸° ê¸°ë°˜ ë¶„í•  ì‹¤íŒ¨. ë¬¸ì¥ ê¸°ë°˜ ë¶„í•  ì‹œë„.")
            sub_chunks = self.chunk_service.split_chunk_by_sentences(
                text_chunk, max_sentences_per_chunk=1
            )
        
        if len(sub_chunks) <= 1:
            logger.error("ì²­í¬ ë¶„í•  ì‹¤íŒ¨. ë²ˆì—­ í¬ê¸°.")
            return f"[ë¶„í•  ë¶ˆê°€ëŠ¥í•œ ê²€ì—´ ì½˜í…ì¸ : {text_chunk[:30]}...]"
        
        # ê° ì„œë¸Œ ì²­í¬ ê°œë³„ ë²ˆì—­ ì‹œë„
        translated_parts = []
        total_sub_chunks = len(sub_chunks)
        successful_sub_chunks = 0
        failed_sub_chunks = 0
        
        logger.info(f"ğŸ”„ ë¶„í•  ì™„ë£Œ: {total_sub_chunks}ê°œ ì„œë¸Œ ì²­í¬ ìƒì„±")
        
        for i, sub_chunk in enumerate(sub_chunks):
            sub_chunk_info = f"ì„œë¸Œ ì²­í¬ {i+1}/{total_sub_chunks}"
            sub_chunk_size = len(sub_chunk.strip())
            sub_chunk_preview = sub_chunk.strip()[:50].replace('\n', ' ') + '...'
            
            logger.info(f"   ğŸš€ {sub_chunk_info} ë²ˆì—­ ì‹œì‘")
            logger.debug(f"      ğŸ“ í¬ê¸°: {sub_chunk_size} ê¸€ì")
            logger.debug(f"      ğŸ“ ë‚´ìš©: {sub_chunk_preview}")
            
            start_time = time.time()
            
            try:
                translated_part = self.translate_text(sub_chunk.strip())
                processing_time = time.time() - start_time
                
                translated_parts.append(translated_part)
                successful_sub_chunks += 1
                
                logger.info(f"   âœ… {sub_chunk_info} ë²ˆì—­ ì„±ê³µ (ì†Œìš”: {processing_time:.2f}ì´ˆ)")
                logger.debug(f"      ğŸ“Š ê²°ê³¼ ê¸¸ì´: {len(translated_part)} ê¸€ì")
                logger.debug(f"      ğŸ“ˆ ì§„í–‰ë¥ : {(i+1)/total_sub_chunks*100:.1f}% ({i+1}/{total_sub_chunks})")
                
            except BtgTranslationException as sub_e:
                processing_time = time.time() - start_time
                
                if "ì½˜í…ì¸  ì•ˆì „ ë¬¸ì œ" in str(sub_e):
                    logger.warning(f"   ğŸ›¡ï¸ {sub_chunk_info} ê²€ì—´ ë°œìƒ (ì†Œìš”: {processing_time:.2f}ì´ˆ)")
                    logger.info(f"   ğŸ”„ ì¬ê·€ ë¶„í•  ì‹œë„ (ê¹Šì´: {current_attempt} â†’ {current_attempt+1})")
                    
                    # ì¬ê·€ì ìœ¼ë¡œ ë” ì‘ê²Œ ë¶„í•  ì‹œë„
                    recursive_result = self._translate_with_recursive_splitting(
                        sub_chunk, max_split_attempts, min_chunk_size, current_attempt + 1
                    )
                    translated_parts.append(recursive_result)
                    
                    if "[ê²€ì—´ë¡œ ì¸í•œ ë²ˆì—­ ì‹¤íŒ¨" in recursive_result:
                        failed_sub_chunks += 1
                        logger.warning(f"   âŒ {sub_chunk_info} ìµœì¢… ì‹¤íŒ¨")
                    else:
                        successful_sub_chunks += 1
                        logger.info(f"   âœ… {sub_chunk_info} ì¬ê·€ ë¶„í•  í›„ ì„±ê³µ")
                else:
                    # ë‹¤ë¥¸ ë²ˆì—­ ì˜¤ë¥˜ì¸ ê²½ìš°
                    failed_sub_chunks += 1
                    logger.error(f"   âŒ {sub_chunk_info} ë²ˆì—­ ì‹¤íŒ¨ (ì†Œìš”: {processing_time:.2f}ì´ˆ): {sub_e}")
                    translated_parts.append(f"[ë²ˆì—­ ì‹¤íŒ¨: {str(sub_e)}]")
                
                logger.debug(f"      ğŸ“ˆ ì§„í–‰ë¥ : {(i+1)/total_sub_chunks*100:.1f}% ({i+1}/{total_sub_chunks})")

        
        # ë²ˆì—­ëœ ë¶€ë¶„ë“¤ì„ ê²°í•©
        final_result = " ".join(translated_parts)
        
        # ë¶„í•  ë²ˆì—­ ì™„ë£Œ ìš”ì•½
        logger.info(f"ğŸ“‹ ë¶„í•  ë²ˆì—­ ì™„ë£Œ ìš”ì•½ (ê¹Šì´: {current_attempt-1})")
        logger.info(f"   ğŸ“Š ì´ ì„œë¸Œ ì²­í¬: {total_sub_chunks}ê°œ")
        logger.info(f"   âœ… ì„±ê³µ: {successful_sub_chunks}ê°œ")
        logger.info(f"   âŒ ì‹¤íŒ¨: {failed_sub_chunks}ê°œ")
        logger.info(f"   ğŸ“ ìµœì¢… ê²°ê³¼ ê¸¸ì´: {len(final_result)} ê¸€ì")
        
        if successful_sub_chunks > 0:
            success_rate = (successful_sub_chunks / total_sub_chunks) * 100
            logger.info(f"   ğŸ“ˆ ì„±ê³µë¥ : {success_rate:.1f}%")
        
        return final_result
    




if __name__ == '__main__':
    # MockGeminiClientì—ì„œ typesë¥¼ ì‚¬ìš©í•˜ë¯€ë¡œ, ì´ ë¸”ë¡ ë‚´ì—ì„œ ì„í¬íŠ¸í•©ë‹ˆë‹¤.
    from google.genai import types # <--- ì—¬ê¸°ì— types ì„í¬íŠ¸ ì¶”ê°€

    print("--- TranslationService í…ŒìŠ¤íŠ¸ ---")
    class MockGeminiClient:
        def __init__(self, auth_credentials, project=None, location=None):
            self.auth_credentials = auth_credentials
            self.api_keys_list = []
            self.current_api_key = None
            self.client = self # ìê¸° ìì‹ ì„ clientë¡œ ì„¤ì • (ì‹¤ì œ Client ê°ì²´ ëŒ€ì‹ )

            if isinstance(auth_credentials, list):
                self.api_keys_list = auth_credentials
                if self.api_keys_list: self.current_api_key = self.api_keys_list[0]
            elif isinstance(auth_credentials, str) and not auth_credentials.startswith('{'):
                self.api_keys_list = [auth_credentials]
                self.current_api_key = auth_credentials
            print(f"MockGeminiClient initialized. API Keys: {self.api_keys_list}, Current Key: {self.current_api_key}")

        def generative_model(self, model_name, system_instruction=None): 
            print(f"  MockGeminiClient: generative_model() í˜¸ì¶œë¨. ëª¨ë¸: {model_name}, ì‹œìŠ¤í…œ ëª…ë ¹ì–´: {'ìˆìŒ' if system_instruction else 'ì—†ìŒ'}")
            self.current_model_name_for_test = model_name
            return self 

        def generate_content(self, contents, generation_config, safety_settings, stream): 
            prompt_text_for_mock = ""
            if isinstance(contents, list) and contents and isinstance(contents[0], types.Part): # types ì‚¬ìš©
                prompt_text_for_mock = "".join(p.text for p in contents if hasattr(p, "text"))
            elif isinstance(contents, str): 
                prompt_text_for_mock = contents


            print(f"  MockGeminiClient.generate_content í˜¸ì¶œë¨ (ëª¨ë¸: {getattr(self, 'current_model_name_for_test', 'N/A')}). í˜„ì¬ í‚¤: {self.current_api_key[:5] if self.current_api_key else 'N/A'}")
            if "ì•ˆì „ ë¬¸ì œ" in prompt_text_for_mock:
                raise GeminiContentSafetyException("Mock ì½˜í…ì¸  ì•ˆì „ ë¬¸ì œ")
            if "ì‚¬ìš©ëŸ‰ ì œí•œ" in prompt_text_for_mock:
                if self.current_api_key == "rate_limit_key":
                    raise GeminiRateLimitException("Mock API ì‚¬ìš©ëŸ‰ ì œí•œ")
            if "ì˜ëª»ëœ ìš”ì²­" in prompt_text_for_mock:
                raise GeminiInvalidRequestException("Mock ì˜ëª»ëœ ìš”ì²­")
            if "ì˜ëª»ëœ í‚¤" in prompt_text_for_mock and self.current_api_key == "invalid_key":
                 raise GeminiInvalidRequestException("Invalid API key (mock)")
            
            mock_part = types.Part(text=f"[ë²ˆì—­ë¨] {prompt_text_for_mock.split('ë²ˆì—­í•  í…ìŠ¤íŠ¸:')[-1].strip()[:50]}...") # types ì‚¬ìš©
            mock_candidate = types.Candidate(content=types.Content(parts=[mock_part]), finish_reason=types.FinishReason.STOP) # types ì‚¬ìš©
            
            class MockResponse:
                def __init__(self, candidates):
                    self.candidates = candidates
                    self.prompt_feedback = None 
                @property
                def text(self):
                    if self.candidates and self.candidates[0].content and self.candidates[0].content.parts:
                        return "".join(p.text for p in self.candidates[0].content.parts if hasattr(p, "text"))
                    return None

            return MockResponse(candidates=[mock_candidate])


        def list_models(self): return [] 

    sample_config_base = {
        "model_name": "gemini-1.5-flash", "temperature": 0.7, "top_p": 0.9,
        "prompts": "ë‹¤ìŒ í…ìŠ¤íŠ¸ë¥¼ í•œêµ­ì–´ë¡œ ë²ˆì—­í•´ì£¼ì„¸ìš”. ë¡œì–´ë¶ ì»¨í…ìŠ¤íŠ¸: {{lorebook_context}}\n\në²ˆì—­í•  í…ìŠ¤íŠ¸:\n{{slot}}",
        "enable_dynamic_lorebook_injection": True, # í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•´ í™œì„±í™”
        "lorebook_json_path_for_injection": "test_lorebook.json", # í…ŒìŠ¤íŠ¸ìš© ë¡œì–´ë¶ ê²½ë¡œ
        "max_lorebook_entries_per_chunk_injection": 3,
        "max_lorebook_chars_per_chunk_injection": 200,
    }

    # 1. ë¡œì–´ë¶ ì£¼ì… í…ŒìŠ¤íŠ¸
    print("\n--- 1. ë¡œì–´ë¶ ì£¼ì… ë²ˆì—­ í…ŒìŠ¤íŠ¸ ---")
    config1 = sample_config_base.copy()
    
    # í…ŒìŠ¤íŠ¸ìš© ë¡œì–´ë¶ íŒŒì¼ ìƒì„±
    test_lorebook_data = [
        {"keyword": "Alice", "description": "ì£¼ì¸ê³µ ì•¨ë¦¬ìŠ¤", "category": "ì¸ë¬¼", "importance": 10, "isSpoiler": False},
        {"keyword": "Bob", "description": "ì•¨ë¦¬ìŠ¤ì˜ ì¹œêµ¬ ë°¥", "category": "ì¸ë¬¼", "importance": 8, "isSpoiler": False}
    ]
    from file_handler import write_json_file, delete_file # write_csv_file -> write_json_file
    test_lorebook_file = Path("test_lorebook.json")
    if test_lorebook_file.exists(): delete_file(test_lorebook_file)
    write_json_file(test_lorebook_file, test_lorebook_data)

    gemini_client_instance = MockGeminiClient(auth_credentials="dummy_api_key")
    translation_service1 = TranslationService(gemini_client_instance, config1)
    text_to_translate1 = "Hello Alice, how are you Bob?"
    try:
        translated1 = translation_service1.translate_text(text_to_translate1)
        print(f"ì›ë³¸: {text_to_translate1}")
        print(f"ë²ˆì—­ ê²°ê³¼: {translated1}")
    except Exception as e:
        print(f"í…ŒìŠ¤íŠ¸ 1 ì˜¤ë¥˜: {e}")
    finally:
        if test_lorebook_file.exists(): delete_file(test_lorebook_file)

    # 2. ë¡œì–´ë¶ ë¹„í™œì„±í™” í…ŒìŠ¤íŠ¸
    print("\n--- 2. ë¡œì–´ë¶ ë¹„í™œì„±í™” í…ŒìŠ¤íŠ¸ ---")
    config2 = sample_config_base.copy()
    config2["enable_dynamic_lorebook_injection"] = False
    translation_service2 = TranslationService(gemini_client_instance, config2)
    text_to_translate2 = "This is a test sentence."
    try:
        translated2 = translation_service2.translate_text(text_to_translate2)
        print(f"ì›ë³¸: {text_to_translate2}")
        print(f"ë²ˆì—­ ê²°ê³¼: {translated2}")
    except Exception as e:
        print(f"í…ŒìŠ¤íŠ¸ 2 ì˜¤ë¥˜: {e}")

    # 3. ì½˜í…ì¸  ì•ˆì „ ë¬¸ì œ í…ŒìŠ¤íŠ¸
    print("\n--- 3. ì½˜í…ì¸  ì•ˆì „ ë¬¸ì œ í…ŒìŠ¤íŠ¸ ---")
    config3 = sample_config_base.copy()
    translation_service3 = TranslationService(gemini_client_instance, config3)
    text_unsafe = "ì•ˆì „ ë¬¸ì œ í…ŒìŠ¤íŠ¸ìš© í…ìŠ¤íŠ¸"
    try:
        translation_service3.translate_text(text_unsafe)
    except BtgTranslationException as e:
        print(f"ì˜ˆìƒëœ ì˜ˆì™¸ ë°œìƒ (ì½˜í…ì¸  ì•ˆì „): {e}")
    except Exception as e:
        print(f"í…ŒìŠ¤íŠ¸ 3 ì˜¤ë¥˜: {type(e).__name__} - {e}")

    print("\n--- TranslationService í…ŒìŠ¤íŠ¸ ì¢…ë£Œ ---")
