# translation_service.py
import time
import random
import re
import csv
import asyncio
from pathlib import Path
from typing import Dict, Any, Optional, List, Union, Callable
import os
import copy # Moved here

try:
    from infrastructure.gemini_client import (
        GeminiClient,
        GeminiContentSafetyException,
        GeminiRateLimitException,
        GeminiApiException,
        GeminiInvalidRequestException,
        GeminiAllApiKeysExhaustedException 
    )
    from infrastructure.file_handler import read_json_file
    from infrastructure.logger_config import setup_logger
    from core.exceptions import BtgTranslationException, BtgApiClientException
    from utils.chunk_service import ChunkService
    from utils.lang_utils import normalize_language_code # Added
    # types ëª¨ë“ˆì€ gemini_clientì—ì„œ ì‚¬ìš©ë˜ë¯€ë¡œ, ì—¬ê¸°ì„œëŠ” ì§ì ‘ì ì¸ ì˜ì¡´ì„±ì´ ì—†ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤. # ë¡œì–´ë¶ -> ìš©ì–´ì§‘
    # ë§Œì•½ ì´ íŒŒì¼ ë‚´ì—ì„œ types.Part ë“±ì„ ì§ì ‘ ì‚¬ìš©í•œë‹¤ë©´, ì•„ë˜ì™€ ê°™ì´ ì„í¬íŠ¸ê°€ í•„ìš”í•©ë‹ˆë‹¤. # ë¡œì–´ë¶ -> ìš©ì–´ì§‘
    from google.genai import types as genai_types
    from core.dtos import GlossaryEntryDTO
except ImportError:
    from infrastructure.gemini_client import (  # type: ignore
        GeminiClient,
        GeminiContentSafetyException,
        GeminiRateLimitException,
        GeminiApiException,
        GeminiInvalidRequestException,
        GeminiAllApiKeysExhaustedException 
    )
    from infrastructure.file_handler import read_json_file  # type: ignore
    from infrastructure.logger_config import setup_logger  # type: ignore
    from core.exceptions import BtgTranslationException, BtgApiClientException  # type: ignore
    from utils.chunk_service import ChunkService  # type: ignore
    from utils.lang_utils import normalize_language_code # type: ignore
    from core.dtos import GlossaryEntryDTO # type: ignore
    from google.genai import types as genai_types # Fallback import

logger = setup_logger(__name__)

def _format_glossary_for_prompt( # í•¨ìˆ˜ëª… ë³€ê²½
    glossary_entries: List[GlossaryEntryDTO], # DTOëŠ” GlossaryEntryDTO (ê²½ëŸ‰í™”ëœ ë²„ì „)
    max_entries: int,
    max_chars: int
) -> str:
    if not glossary_entries:
        return "ìš©ì–´ì§‘ ì»¨í…ìŠ¤íŠ¸ ì—†ìŒ" # ë©”ì‹œì§€ ë³€ê²½

    selected_entries_str = []
    current_chars = 0
    entries_count = 0

    # ë“±ì¥ íšŸìˆ˜ ë§ì€ ìˆœ, ê°™ìœ¼ë©´ í‚¤ì›Œë“œ ê°€ë‚˜ë‹¤ ìˆœìœ¼ë¡œ ì •ë ¬
    sorted_entries = sorted(glossary_entries, key=lambda x: (-x.occurrence_count, x.keyword.lower()))

    for entry in sorted_entries:
        if entries_count >= max_entries:
            break
        
        # í˜„ì¬ í•­ëª© ì¶”ê°€ ì‹œ ìµœëŒ€ ê¸€ì ìˆ˜ ì´ˆê³¼í•˜ë©´ ì¤‘ë‹¨ (ë‹¨, ìµœì†Œ 1ê°œëŠ” í¬í•¨ë˜ë„ë¡)
        # DTOì—ì„œ source_languageê°€ ì œê±°ë˜ì—ˆìœ¼ë¯€ë¡œ í•´ë‹¹ ë¶€ë¶„ í¬ë§·íŒ…ì—ì„œ ì œì™¸
        entry_str = (f"- {entry.keyword} "
                     f"-> {entry.translated_keyword} ({entry.target_language}) "
                     f"(ë“±ì¥: {entry.occurrence_count}íšŒ)")
        if current_chars + len(entry_str) > max_chars and entries_count > 0:
            break
        
        selected_entries_str.append(entry_str)
        current_chars += len(entry_str) + 1 # +1 for newline
        entries_count += 1

    if not selected_entries_str:
        return "ìš©ì–´ì§‘ ì»¨í…ìŠ¤íŠ¸ ì—†ìŒ (ì œí•œìœ¼ë¡œ ì¸í•´ ì„ íƒëœ í•­ëª© ì—†ìŒ)" # ë©”ì‹œì§€ ë³€ê²½
        
    return "\n".join(selected_entries_str)

def _inject_slots_into_history(
    history: List[genai_types.Content], 
    replacements: Dict[str, str]
) -> tuple[List[genai_types.Content], bool]:
    """
    íˆìŠ¤í† ë¦¬ ë‚´ì˜ Content ê°ì²´ë“¤ì„ ìˆœíšŒí•˜ë©° ìŠ¬ë¡¯({{slot}} ë“±)ì„ ì‹¤ì œ ê°’ìœ¼ë¡œ ì¹˜í™˜í•©ë‹ˆë‹¤.
    ë°˜í™˜ê°’: (ìˆ˜ì •ëœ íˆìŠ¤í† ë¦¬, ì¹˜í™˜ ë°œìƒ ì—¬ë¶€)
    """
    # ê¹Šì€ ë³µì‚¬ë¡œ ì›ë³¸ ì˜¤ì—¼ ë°©ì§€
    new_history = copy.deepcopy(history)
    replacement_occurred = False

    for content in new_history:
        if not hasattr(content, 'parts'):
            continue
            
        for part in content.parts:
            if hasattr(part, 'text') and part.text:
                original_text = part.text
                modified_text = original_text
                
                for key, value in replacements.items():
                    if key in modified_text:
                        modified_text = modified_text.replace(key, value)
                        replacement_occurred = True
                
                if original_text != modified_text:
                    part.text = modified_text
    
    return new_history, replacement_occurred

class TranslationService:
    def __init__(self, gemini_client: GeminiClient, config: Dict[str, Any]):
        self.gemini_client = gemini_client
        self.config = config
        self.chunk_service = ChunkService()
        self.glossary_entries_for_injection: List[GlossaryEntryDTO] = [] # Renamed and type changed
        self.stop_check_callback: Optional[Callable[[], bool]] = None  # ì¤‘ë‹¨ ìš”ì²­ í™•ì¸ìš© ì½œë°±

        if self.config.get("enable_dynamic_glossary_injection", False): # Key changed
            self._load_glossary_data() # í•¨ìˆ˜ëª… ë³€ê²½
            logger.info("ë™ì  ìš©ì–´ì§‘ ì£¼ì… í™œì„±í™”ë¨. ìš©ì–´ì§‘ ë°ì´í„° ë¡œë“œ ì‹œë„.") # ë©”ì‹œì§€ ë³€ê²½
        else:
            logger.info("ë™ì  ìš©ì–´ì§‘ ì£¼ì… ë¹„í™œì„±í™”ë¨. ìš©ì–´ì§‘ ì»¨í…ìŠ¤íŠ¸ ì—†ì´ ë²ˆì—­í•©ë‹ˆë‹¤.") # ë©”ì‹œì§€ ë³€ê²½

    def _load_glossary_data(self): # í•¨ìˆ˜ëª… ë³€ê²½
        # ë°ì´í„°ë¥¼ ë¡œë“œí•˜ê¸° ì „ì— í•­ìƒ ëª©ë¡ì„ ì´ˆê¸°í™”í•©ë‹ˆë‹¤.
        self.glossary_entries_for_injection = []
        
        # í†µí•©ëœ ìš©ì–´ì§‘ ê²½ë¡œ ì‚¬ìš©
        lorebook_json_path_str = self.config.get("glossary_json_path")
        if lorebook_json_path_str and os.path.exists(lorebook_json_path_str):
            lorebook_json_path = Path(lorebook_json_path_str)
            try:
                raw_data = read_json_file(lorebook_json_path)
                if isinstance(raw_data, list):
                    for item_dict in raw_data:
                        if isinstance(item_dict, dict) and \
                           "keyword" in item_dict and \
                           "translated_keyword" in item_dict and \
                           "target_language" in item_dict:
                            try:
                                # target_language ì •ê·œí™” ë¡œë“œ ì‹œ ë¯¸ë¦¬ ìˆ˜í–‰
                                raw_lang = item_dict.get("target_language", "")
                                normalized_lang = normalize_language_code(raw_lang)
                                
                                entry = GlossaryEntryDTO( # Explicitly use GlossaryEntryDTO
                                    keyword=item_dict.get("keyword", ""),
                                    translated_keyword=item_dict.get("translated_keyword", ""),
                                    target_language=normalized_lang, # ì •ê·œí™”ëœ ì½”ë“œ ì‚¬ìš©
                                    occurrence_count=int(item_dict.get("occurrence_count", 0))
                                )
                                if all([entry.keyword, entry.translated_keyword, entry.target_language]): # í•„ìˆ˜ í•„ë“œ í™•ì¸ (source_language ì œê±°)
                                    self.glossary_entries_for_injection.append(entry)
                                else:
                                    logger.warning(f"ê²½ëŸ‰ ìš©ì–´ì§‘ í•­ëª©ì— í•„ìˆ˜ í•„ë“œ ëˆ„ë½: {item_dict}")
                            except (TypeError, ValueError) as e_dto:
                                logger.warning(f"ìš©ì–´ì§‘ í•­ëª© DTO ë³€í™˜ ì¤‘ ì˜¤ë¥˜: {item_dict}, ì˜¤ë¥˜: {e_dto}") # ë©”ì‹œì§€ ë³€ê²½
                        else:
                            logger.warning(f"ì˜ëª»ëœ ìš©ì–´ì§‘ í•­ëª© í˜•ì‹ (ë”•ì…”ë„ˆë¦¬ê°€ ì•„ë‹ˆê±°ë‚˜ í•„ìˆ˜ í‚¤ 'keyword' ë˜ëŠ” 'translated_keyword' ëˆ„ë½) ê±´ë„ˆëœ€: {item_dict}") # ë©”ì‹œì§€ ë³€ê²½
                    logger.info(f"{len(self.glossary_entries_for_injection)}ê°œì˜ ìš©ì–´ì§‘ í•­ëª©ì„ ë¡œë“œí–ˆìŠµë‹ˆë‹¤: {lorebook_json_path}") # ë©”ì‹œì§€ ë³€ê²½
                else: # type: ignore
                    logger.error(f"ìš©ì–´ì§‘ JSON íŒŒì¼ì´ ë¦¬ìŠ¤íŠ¸ í˜•ì‹ì´ ì•„ë‹™ë‹ˆë‹¤: {lorebook_json_path}, íƒ€ì…: {type(raw_data)}") # ë©”ì‹œì§€ ë³€ê²½
            except Exception as e:
                logger.error(f"ìš©ì–´ì§‘ JSON íŒŒì¼ ì²˜ë¦¬ ì¤‘ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜ ({lorebook_json_path}): {e}", exc_info=True) # ë©”ì‹œì§€ ë³€ê²½
                self.glossary_entries_for_injection = []
        else:
            logger.info(f"ìš©ì–´ì§‘ JSON íŒŒì¼({lorebook_json_path_str})ì´ ì„¤ì •ë˜ì§€ ì•Šì•˜ê±°ë‚˜ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ë™ì  ì£¼ì…ì„ ìœ„í•´ ìš©ì–´ì§‘ì„ ì‚¬ìš©í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.") # ë©”ì‹œì§€ ë³€ê²½
            self.glossary_entries_for_injection = []

    def _construct_prompt(self, chunk_text: str) -> str:
        prompt_template = self.config.get("prompts", "Translate to Korean: {{slot}}")
        if isinstance(prompt_template, (list, tuple)):
            prompt_template = prompt_template[0] if prompt_template else "Translate to Korean: {{slot}}"

        # [Strict Mode] í•„ìˆ˜ í”Œë ˆì´ìŠ¤í™€ë” ê²€ì¦
        if "{{slot}}" not in prompt_template:
            raise BtgTranslationException("ë²ˆì—­ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ì— í•„ìˆ˜ í”Œë ˆì´ìŠ¤í™€ë” '{{slot}}'ì´ ëˆ„ë½ë˜ì—ˆìŠµë‹ˆë‹¤. ì‘ì—…ì„ ì¤‘ë‹¨í•©ë‹ˆë‹¤.")

        # [Strict Mode] ìš©ì–´ì§‘ ì£¼ì… í™œì„±í™” ì‹œ í”Œë ˆì´ìŠ¤í™€ë” ê²€ì¦
        if self.config.get("enable_dynamic_glossary_injection", False) and "{{glossary_context}}" not in prompt_template:
            raise BtgTranslationException("ë™ì  ìš©ì–´ì§‘ ì£¼ì…ì´ í™œì„±í™”ë˜ì—ˆìœ¼ë‚˜, í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ì— '{{glossary_context}}' í”Œë ˆì´ìŠ¤í™€ë”ê°€ ì—†ìŠµë‹ˆë‹¤. ì‘ì—…ì„ ì¤‘ë‹¨í•©ë‹ˆë‹¤.")

        final_prompt = prompt_template

        # Determine the source language for the current chunk to filter glossary entries
        config_source_lang = self.config.get("novel_language") # í†µí•©ëœ ì„¤ì • ì‚¬ìš©
        # Fallback language from config, with a hardcoded default if the config key itself is missing
        config_fallback_lang = self.config.get("novel_language_fallback", "ja") # í†µí•©ëœ í´ë°± ì„¤ì • ì‚¬ìš©

        # "auto" ëª¨ë“œì¼ ë•Œ, LLMì´ ì–¸ì–´ë¥¼ ê°ì§€í•˜ê³  ìš©ì–´ì§‘ì„ í•„í„°ë§í•˜ë„ë¡ í”„ë¡¬í”„íŠ¸ê°€ êµ¬ì„±ë©ë‹ˆë‹¤.
        # Python ë‹¨ì—ì„œ current_source_lang_for_translationì„ í™•ì •í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.
        # ë¡œê¹…ì´ë‚˜ íŠ¹ì • ì¡°ê±´ë¶€ ë¡œì§ì„ ìœ„í•´ì„  ì—¬ì „íˆ í•„ìš”í•  ìˆ˜ ìˆìœ¼ë‚˜, ìš©ì–´ì§‘ í•„í„°ë§ì€ LLMìœ¼ë¡œ ë„˜ì–´ê°‘ë‹ˆë‹¤.
        current_source_lang_for_glossary_filtering: Optional[str] = None

        if config_source_lang == "auto":
            logger.info(f"ë²ˆì—­ ì¶œë°œ ì–¸ì–´ ì„¤ì •: 'auto'. LLMì´ í”„ë¡¬í”„íŠ¸ ë‚´ì—ì„œ ì–¸ì–´ë¥¼ ê°ì§€í•˜ê³  ìš©ì–´ì§‘ì„ ì ìš©í•˜ë„ë¡ í•©ë‹ˆë‹¤.") # ë©”ì‹œì§€ ë³€ê²½
            # current_source_lang_for_glossary_filteringëŠ” Noneìœ¼ë¡œ ìœ ì§€í•˜ê±°ë‚˜ "auto"ë¡œ ì„¤ì •.
            # ìš©ì–´ì§‘ í•„í„°ë§ì€ LLMì˜ ì—­í• ì´ ë©ë‹ˆë‹¤.
        elif config_source_lang and isinstance(config_source_lang, str) and config_source_lang.strip(): # Specific language code provided
            current_source_lang_for_glossary_filtering = config_source_lang
            logger.info(f"ëª…ì‹œì  ë²ˆì—­ ì¶œë°œ ì–¸ì–´ '{current_source_lang_for_glossary_filtering}' ì‚¬ìš©. ìš©ì–´ì§‘ë„ ì´ ì–¸ì–´ ê¸°ì¤€ìœ¼ë¡œ í•„í„°ë§ë©ë‹ˆë‹¤.") # ë©”ì‹œì§€ ë³€ê²½
        else: # config_source_lang is None, empty string, or not "auto"
            current_source_lang_for_glossary_filtering = config_fallback_lang
            logger.warning(f"ë²ˆì—­ ì¶œë°œ ì–¸ì–´ê°€ ìœ íš¨í•˜ê²Œ ì„¤ì •ë˜ì§€ ì•Šì•˜ê±°ë‚˜ 'auto'ê°€ ì•„ë‹™ë‹ˆë‹¤. í´ë°± ì–¸ì–´ '{current_source_lang_for_glossary_filtering}'ë¥¼ ìš©ì–´ì§‘ í•„í„°ë§ì— ì‚¬ìš©.")

        # 1. Dynamic Glossary Injection
        if self.config.get("enable_dynamic_glossary_injection", False) and \
           self.glossary_entries_for_injection and \
           "{{glossary_context}}" in final_prompt: # Placeholder changed
            
            relevant_entries_for_chunk: List[GlossaryEntryDTO] = []
            chunk_text_lower = chunk_text.lower() # For case-insensitive keyword matching
            # ìµœì¢… ë²ˆì—­ ëª©í‘œ ì–¸ì–´ (ì˜ˆ: "ko")
            # ì´ ì„¤ì •ì€ config.json ë˜ëŠ” ë‹¤ë¥¸ ë°©ì‹ìœ¼ë¡œ ì œê³µë˜ì–´ì•¼ í•©ë‹ˆë‹¤.
            # final_target_lang ì„¤ì • ì‹œ ì •ê·œí™” ì ìš©
            final_target_lang = normalize_language_code(self.config.get("target_translation_language", "ko"))

            if config_source_lang == "auto":
                # "auto" ëª¨ë“œ: ì²­í¬ì˜ ì–¸ì–´ëŠ” LLMì´ ê°ì§€.
                # ìš©ì–´ì§‘ í•­ëª©ì˜ target_languageê°€ ìµœì¢… ë²ˆì—­ ëª©í‘œ ì–¸ì–´ì™€ ì¼ì¹˜í•˜ëŠ” ê²ƒë§Œ ê³ ë ¤.
                # source_language í•„í„°ë§ì€ LLMì˜ ë¬¸ë§¥ ì´í•´ì— ë§¡ê¸°ê±°ë‚˜, ì—¬ê¸°ì„œ ê°„ë‹¨í•œ í‚¤ì›Œë“œ ë§¤ì¹­ë§Œ ìˆ˜í–‰.
                logger.info(f"ìë™ ì–¸ì–´ ê°ì§€ ëª¨ë“œ: ìš©ì–´ì§‘ì€ í‚¤ì›Œë“œ ì¼ì¹˜ ë° ìµœì¢… ëª©í‘œ ì–¸ì–´({final_target_lang}) ì¼ì¹˜ë¡œ í•„í„°ë§ í›„ LLMì— ì „ë‹¬.") # ë©”ì‹œì§€ ë³€ê²½
                for entry in self.glossary_entries_for_injection:
                    # entry.target_languageëŠ” _load_glossary_dataì—ì„œ ì´ë¯¸ ì •ê·œí™”ë¨
                    if entry.target_language == final_target_lang and \
                       entry.keyword.lower() in chunk_text_lower:
                        relevant_entries_for_chunk.append(entry)
            else:
                # ëª…ì‹œì  ì–¸ì–´ ì„¤ì • ëª¨ë“œ: Pythonì—ì„œ ì–¸ì–´ ë° í‚¤ì›Œë“œ ê¸°ë°˜ìœ¼ë¡œ í•„í„°ë§.
                logger.info(f"ëª…ì‹œì  ì–¸ì–´ ëª¨ë“œ ('{current_source_lang_for_glossary_filtering}'): ìš©ì–´ì§‘ì„ ì¶œë°œì–´/ë„ì°©ì–´ ë° í‚¤ì›Œë“œ ê¸°ì¤€ìœ¼ë¡œ í•„í„°ë§.") # ë©”ì‹œì§€ ë³€ê²½
                for entry in self.glossary_entries_for_injection:
                    # source_language í•„í„°ë§ ì œê±°. DTOì— í•´ë‹¹ í•„ë“œê°€ ì—†ìœ¼ë¯€ë¡œ.
                    if entry.target_language == final_target_lang and \
                       entry.keyword.lower() in chunk_text_lower:
                        relevant_entries_for_chunk.append(entry)
                    # source_language ê´€ë ¨ ë¡œê¹… ì œê±°
                    elif not (entry.target_language == final_target_lang): # target_language ë¶ˆì¼ì¹˜ ë¡œê¹…ì€ ìœ ì§€
                        logger.debug(f"ìš©ì–´ì§‘ í•­ëª© '{entry.keyword}' ê±´ë„ˆëœ€: ë„ì°© ì–¸ì–´ ë¶ˆì¼ì¹˜ (ìš©ì–´ì§‘TL: {entry.target_language}, ìµœì¢…TL: {final_target_lang}).")
                        continue
            
            logger.debug(f"í˜„ì¬ ì²­í¬ì— ëŒ€í•´ {len(relevant_entries_for_chunk)}ê°œì˜ ê´€ë ¨ ìš©ì–´ì§‘ í•­ëª© ë°œê²¬.") # ë©”ì‹œì§€ ë³€ê²½

            # 1.b. Format the relevant entries for the prompt
            max_entries = self.config.get("max_glossary_entries_per_chunk_injection", 3) # Key changed
            max_chars = self.config.get("max_glossary_chars_per_chunk_injection", 500) # Key changed
            
            formatted_glossary_context = _format_glossary_for_prompt( # í•¨ìˆ˜ëª… ë³€ê²½
                relevant_entries_for_chunk, max_entries, max_chars # Pass only relevant entries
            )
            
            # Check if actual content was formatted (not just "ì—†ìŒ" messages)
            final_prompt = final_prompt.replace("{{glossary_context}}", formatted_glossary_context) # Placeholder changed
        else:
            if "{{glossary_context}}" in final_prompt: # Placeholder changed
                 final_prompt = final_prompt.replace("{{glossary_context}}", "ìš©ì–´ì§‘ ì»¨í…ìŠ¤íŠ¸ ì—†ìŒ (ì£¼ì… ë¹„í™œì„±í™” ë˜ëŠ” í•´ë‹¹ í•­ëª© ì—†ìŒ)") # Placeholder changed
                 logger.debug("ë™ì  ìš©ì–´ì§‘ ì£¼ì… ë¹„í™œì„±í™” ë˜ëŠ” í”Œë ˆì´ìŠ¤í™€ë” ë¶€ì¬ë¡œ 'ì»¨í…ìŠ¤íŠ¸ ì—†ìŒ' ë©”ì‹œì§€ ì‚¬ìš©.")
        
        # 3. Main content slot - This should be done *after* all other placeholders are processed.
        final_prompt = final_prompt.replace("{{slot}}", chunk_text)
        return final_prompt

    def set_stop_check_callback(self, callback: Optional[Callable[[], bool]]) -> None:
        """
        ì¤‘ë‹¨ ìš”ì²­ì„ í™•ì¸í•˜ëŠ” ì½œë°± í•¨ìˆ˜ë¥¼ ì„¤ì •í•©ë‹ˆë‹¤.
        
        Args:
            callback: ì¤‘ë‹¨ ìš”ì²­ ì—¬ë¶€ë¥¼ ë°˜í™˜í•˜ëŠ” ì½œë°± í•¨ìˆ˜
        """
        self.stop_check_callback = callback

    # ============================================================================
    # ë¹„ë™ê¸° ë©”ì„œë“œ (Phase 2: asyncio ë§ˆì´ê·¸ë ˆì´ì…˜)
    # ============================================================================

    async def translate_chunk_async(
        self,
        chunk_text: str,
        stream: bool = False
    ) -> str:
        """
        ë¹„ë™ê¸° ì²­í¬ ë²ˆì—­ ë©”ì„œë“œ (ì§„ì •í•œ ë¹„ë™ê¸° êµ¬í˜„)
        
        Timeoutì€ GeminiClientì˜ http_optionsì— ì„¤ì •ë˜ì–´ ëª¨ë“  API í˜¸ì¶œì— ìë™ ì ìš©ë©ë‹ˆë‹¤.
        
        Args:
            chunk_text: ë²ˆì—­í•  í…ìŠ¤íŠ¸
            stream: ìŠ¤íŠ¸ë¦¬ë° ì—¬ë¶€
            
        Returns:
            ë²ˆì—­ëœ í…ìŠ¤íŠ¸
            
        Raises:
            asyncio.CancelledError: ì‘ì—… ì·¨ì†Œë¨
            BtgTranslationException: ë²ˆì—­ ì‹¤íŒ¨
        """
        # ğŸ“ ì¤‘ë‹¨ ì²´í¬: ì‘ì—… ì‹œì‘ ì „
        if self.stop_check_callback and self.stop_check_callback():
            logger.info("translate_chunk_async: ì¤‘ë‹¨ ìš”ì²­ ê°ì§€ë¨ (ì‘ì—… ì‹œì‘ ì „)")
            raise asyncio.CancelledError("ë²ˆì—­ ì¤‘ë‹¨ ìš”ì²­ë¨")
        
        # âœ¨ ë°©ì–´ì  ì²´í¬í¬ì¸íŠ¸: asyncio ì·¨ì†Œ í™•ì¸ ê°•ì œ
        await asyncio.sleep(0)
        
        if not chunk_text.strip():
            logger.debug("translate_chunk_async: ì…ë ¥ í…ìŠ¤íŠ¸ê°€ ë¹„ì–´ ìˆì–´ ë¹ˆ ë¬¸ìì—´ ë°˜í™˜.")
            return ""
        
        # ì†Œì„¤ ë³¸ë¬¸ ë¯¸ë¦¬ë³´ê¸° ë¡œê¹…
        text_preview = chunk_text[:100].replace('\n', ' ')
        logger.info(f"ë¹„ë™ê¸° ì²­í¬ ë²ˆì—­ ìš”ì²­: \"{text_preview}{'...' if len(chunk_text) > 100 else ''}\"")
        
        try:
            # ì§„ì •í•œ ë¹„ë™ê¸° ë©”ì„œë“œ í˜¸ì¶œ (GeminiClientì˜ http_options timeoutì— ì˜ì¡´)
            result = await self.translate_text_with_content_safety_retry_async(chunk_text)
            
            # ğŸ“ ì¤‘ë‹¨ ì²´í¬: API ì‘ë‹µ í›„
            if self.stop_check_callback and self.stop_check_callback():
                logger.info("translate_chunk_async: ì¤‘ë‹¨ ìš”ì²­ ê°ì§€ë¨ (ì‘ë‹µ í›„)")
                raise asyncio.CancelledError("ë²ˆì—­ ì¤‘ë‹¨ ìš”ì²­ë¨")
            
            return result
        except asyncio.CancelledError:
            logger.info("ë¹„ë™ê¸° ë²ˆì—­ì´ ì·¨ì†Œë¨")
            raise
        except BtgApiClientException as e_api:
            if isinstance(e_api.original_exception, GeminiAllApiKeysExhaustedException):
                logger.critical(f"ëª¨ë“  API í‚¤ ì†Œì§„ìœ¼ë¡œ ë²ˆì—­ ì¤‘ë‹¨: {e_api}")
                raise # Re-raise BtgApiClientException to stop the process
            
            logger.error(f"ë¹„ë™ê¸° ë²ˆì—­ ì¤‘ API ì˜¤ë¥˜: {type(e_api).__name__} - {e_api}", exc_info=True)
            raise BtgTranslationException(f"ë¹„ë™ê¸° ë²ˆì—­ ì¤‘ API ì˜¤ë¥˜: {e_api}", original_exception=e_api) from e_api
        except Exception as e:
            logger.error(f"ë¹„ë™ê¸° ë²ˆì—­ ì¤‘ ì˜¤ë¥˜: {type(e).__name__} - {e}", exc_info=True)
            if isinstance(e, BtgTranslationException):
                raise
            raise BtgTranslationException(f"ë¹„ë™ê¸° ë²ˆì—­ ì¤‘ ì˜¤ë¥˜: {e}", original_exception=e) from e

    # ============================================================================
    # ë¹„ë™ê¸° ë©”ì„œë“œ (Phase 2: asyncio ë§ˆì´ê·¸ë ˆì´ì…˜)
    # ============================================================================

    async def translate_text_async(self, text_chunk: str, stream: bool = False) -> str:
        """
        ë¹„ë™ê¸° í…ìŠ¤íŠ¸ ë²ˆì—­ ë©”ì„œë“œ (translate_textì˜ ë¹„ë™ê¸° ë²„ì „)
        
        Args:
            text_chunk: ë²ˆì—­í•  í…ìŠ¤íŠ¸
            stream: ìŠ¤íŠ¸ë¦¬ë° ì—¬ë¶€
            
        Returns:
            ë²ˆì—­ëœ í…ìŠ¤íŠ¸
            
        Raises:
            asyncio.CancelledError: ì‘ì—…ì´ ì·¨ì†Œëœ ê²½ìš°
            BtgTranslationException: ë²ˆì—­ ì‹¤íŒ¨
        """
        if not text_chunk.strip():
            logger.debug("translate_text_async: ì…ë ¥ í…ìŠ¤íŠ¸ê°€ ë¹„ì–´ ìˆì–´ ë¹ˆ ë¬¸ìì—´ ë°˜í™˜.")
            return ""
        
        # ğŸ“ ì¤‘ë‹¨ ì²´í¬: ì‘ì—… ì‹œì‘ ì „ (asyncio.CancelledError ë°œìƒ)
        if self.stop_check_callback and self.stop_check_callback():
            logger.info("translate_text_async: ì¤‘ë‹¨ ìš”ì²­ ê°ì§€ë¨ (ì‘ì—… ì‹œì‘ ì „)")
            raise asyncio.CancelledError("ë²ˆì—­ ì¤‘ë‹¨ ìš”ì²­ë¨")
        
        # âœ¨ ë°©ì–´ì  ì²´í¬í¬ì¸íŠ¸: asyncio ì·¨ì†Œ í™•ì¸ ê°•ì œ
        await asyncio.sleep(0)
        
        text_preview = text_chunk[:100].replace('\n', ' ')
        logger.info(f"ë¹„ë™ê¸° ë²ˆì—­ ìš”ì²­: \"{text_preview}{'...' if len(text_chunk) > 100 else ''}\"")
        
        # ìš©ì–´ì§‘ ë° í”„ë¡¬í”„íŠ¸ ì¤€ë¹„ (ë™ê¸° ë©”ì„œë“œì™€ ë™ì¼)
        glossary_context_str = "ìš©ì–´ì§‘ ì»¨í…ìŠ¤íŠ¸ ì—†ìŒ"
        
        if self.config.get("enable_dynamic_glossary_injection", False) and self.glossary_entries_for_injection:
            logger.info("ìš©ì–´ì§‘ ì»¨í…ìŠ¤íŠ¸ ì£¼ì… í™œì„±í™”ë¨ (ì²­í¬ ë‚´ ê´€ë ¨ í‚¤ì›Œë“œ ì²´í¬).")
            chunk_text_lower = text_chunk.lower()
            # target_language ì •ê·œí™” ì ìš©
            final_target_lang = normalize_language_code(self.config.get("target_translation_language", "ko"))
            relevant_entries = []
            
            for entry in self.glossary_entries_for_injection:
                # entry.target_languageëŠ” _load_glossary_dataì—ì„œ ì´ë¯¸ ì •ê·œí™”ë¨
                if entry.target_language == final_target_lang and entry.keyword.lower() in chunk_text_lower:
                    relevant_entries.append(entry)
            
            max_entries = self.config.get("max_glossary_entries_per_chunk_injection", 3)
            max_chars = self.config.get("max_glossary_chars_per_chunk_injection", 500)
            glossary_context_str = _format_glossary_for_prompt(relevant_entries, max_entries, max_chars)
            
            if relevant_entries:
                logger.info(f"API ìš”ì²­ì— ì£¼ì…í•  ìš©ì–´ì§‘ ì»¨í…ìŠ¤íŠ¸ ìƒì„±ë¨. ë‚´ìš© ì¼ë¶€: {glossary_context_str[:100]}...")
        
        replacements = {
            "{{slot}}": text_chunk,
            "{{glossary_context}}": glossary_context_str
        }

        api_prompt_for_gemini_client: List[genai_types.Content] = []
        api_system_instruction: Optional[str] = None

        if self.config.get("enable_prefill_translation", False):
            logger.info("í”„ë¦¬í•„ ë²ˆì—­ ëª¨ë“œ í™œì„±í™”ë¨ (Slot Injection ì²´í¬).")
            api_system_instruction = self.config.get("prefill_system_instruction", "")
            prefill_cached_history_raw = self.config.get("prefill_cached_history", [])
            base_history: List[genai_types.Content] = []
            
            if isinstance(prefill_cached_history_raw, list):
                for item in prefill_cached_history_raw:
                    if isinstance(item, dict) and "role" in item and "parts" in item:
                        sdk_parts = []
                        for part_item in item.get("parts", []):
                            if isinstance(part_item, str):
                                sdk_parts.append(genai_types.Part.from_text(text=part_item))
                        if sdk_parts:
                            base_history.append(genai_types.Content(role=item["role"], parts=sdk_parts))

            injected_history, injected = _inject_slots_into_history(base_history, replacements)

            if injected:
                logger.info("íˆìŠ¤í† ë¦¬ ë‚´ë¶€ì—ì„œ '{{slot}}'ì´ ê°ì§€ë˜ì–´ ì›ë¬¸ì„ ì£¼ì…í–ˆìŠµë‹ˆë‹¤ (Jailbreak ëª¨ë“œ).")
                api_prompt_for_gemini_client = injected_history
                if api_prompt_for_gemini_client and api_prompt_for_gemini_client[-1].role == "model":
                    api_prompt_for_gemini_client.append(
                        genai_types.Content(role="user", parts=[genai_types.Part.from_text(text=" ")])
                    )
            else:
                api_prompt_for_gemini_client = injected_history
                user_prompt_str = self._construct_prompt(text_chunk)
                api_prompt_for_gemini_client.append(
                    genai_types.Content(role="user", parts=[genai_types.Part.from_text(text=user_prompt_str)])
                )
        else:
            user_prompt_str = self._construct_prompt(text_chunk)
            api_prompt_for_gemini_client = [
                genai_types.Content(role="user", parts=[genai_types.Part.from_text(text=user_prompt_str)])
            ]

        try:
            translated_text_from_api = await self.gemini_client.generate_text_async(
                prompt=api_prompt_for_gemini_client,
                model_name=self.config.get("model_name", "gemini-2.0-flash"),
                generation_config_dict={
                    "temperature": self.config.get("temperature", 0.7),
                    "top_p": self.config.get("top_p", 0.9),
                    "thinking_level": self.config.get("thinking_level", "high")
                },
                thinking_budget=self.config.get("thinking_budget", None),
                system_instruction_text=api_system_instruction,
                stream=stream
            )

            if translated_text_from_api is None:
                raise GeminiContentSafetyException("APIë¡œë¶€í„° ì‘ë‹µì„ ë°›ì§€ ëª»í–ˆìŠµë‹ˆë‹¤ (None ë°˜í™˜).")

            if not translated_text_from_api.strip() and text_chunk.strip():
                raise GeminiContentSafetyException("APIê°€ ë¹„ì–´ìˆì§€ ì•Šì€ ì…ë ¥ì— ëŒ€í•´ ë¹ˆ ë²ˆì—­ ê²°ê³¼ë¥¼ ë°˜í™˜í–ˆìŠµë‹ˆë‹¤.")

            return translated_text_from_api.strip()

        except asyncio.CancelledError:
            logger.info("ë¹„ë™ê¸° ë²ˆì—­ì´ ì·¨ì†Œë˜ì—ˆìŠµë‹ˆë‹¤")
            raise
        except GeminiContentSafetyException as e_safety:
            raise BtgTranslationException(f"ì½˜í…ì¸  ì•ˆì „ ë¬¸ì œë¡œ ë²ˆì—­í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ({e_safety})", original_exception=e_safety) from e_safety
        except GeminiAllApiKeysExhaustedException as e_keys:
            raise BtgApiClientException(f"ëª¨ë“  API í‚¤ë¥¼ ì‚¬ìš©í–ˆìœ¼ë‚˜ ìš”ì²­ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ({e_keys})", original_exception=e_keys) from e_keys
        except GeminiRateLimitException as e_rate:
            raise BtgApiClientException(f"API ì‚¬ìš©ëŸ‰ ì œí•œì„ ì´ˆê³¼í–ˆìŠµë‹ˆë‹¤. ({e_rate})", original_exception=e_rate) from e_rate
        except GeminiInvalidRequestException as e_invalid:
            raise BtgApiClientException(f"ì˜ëª»ëœ API ìš”ì²­ì…ë‹ˆë‹¤: {e_invalid}", original_exception=e_invalid) from e_invalid
        except GeminiApiException as e_api:
            raise BtgApiClientException(f"API í˜¸ì¶œ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e_api}", original_exception=e_api) from e_api
        except Exception as e:
            raise BtgTranslationException(f"ë²ˆì—­ ì¤‘ ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}", original_exception=e) from e

    async def translate_text_with_content_safety_retry_async(
        self, 
        text_chunk: str, 
        max_split_attempts: int = 3,
        min_chunk_size: int = 100
    ) -> str:
        """
        ë¹„ë™ê¸° ë²„ì „: ì½˜í…ì¸  ì•ˆì „ ì˜¤ë¥˜ ë°œìƒì‹œ ì²­í¬ë¥¼ ë¶„í• í•˜ì—¬ ì¬ì‹œë„í•˜ëŠ” ë²ˆì—­ ë©”ì„œë“œ
        
        Args:
            text_chunk: ë²ˆì—­í•  í…ìŠ¤íŠ¸
            max_split_attempts: ìµœëŒ€ ë¶„í•  ì‹œë„ íšŸìˆ˜
            min_chunk_size: ìµœì†Œ ì²­í¬ í¬ê¸°
            
        Returns:
            ë²ˆì—­ëœ í…ìŠ¤íŠ¸ (ì‹¤íŒ¨í•œ ë¶€ë¶„ì€ ì˜¤ë¥˜ ë©”ì‹œì§€ë¡œ ëŒ€ì²´)
        """
        try:
            return await self.translate_text_async(text_chunk)
        except BtgTranslationException as e:
            if not ("ì½˜í…ì¸  ì•ˆì „ ë¬¸ì œ" in str(e)):
                raise e
            
            logger.warning(f"ì½˜í…ì¸  ì•ˆì „ ë¬¸ì œ ê°ì§€. ë¹„ë™ê¸° ì²­í¬ ë¶„í•  ì¬ì‹œë„ ì‹œì‘: {str(e)}")
            return await self._translate_with_recursive_splitting_async(
                text_chunk, max_split_attempts, min_chunk_size, current_attempt=1
            )

    async def _translate_with_recursive_splitting_async(
        self,
        text_chunk: str,
        max_split_attempts: int,
        min_chunk_size: int,
        current_attempt: int = 1
    ) -> str:
        if current_attempt > max_split_attempts:
            logger.error(f"ìµœëŒ€ ë¶„í•  ì‹œë„ íšŸìˆ˜({max_split_attempts})ì— ë„ë‹¬. ë²ˆì—­ ì‹¤íŒ¨.")
            return f"[ë²ˆì—­ ì˜¤ë¥˜ë¡œ ì¸í•œ ì‹¤íŒ¨: ìµœëŒ€ ë¶„í•  ì‹œë„ ì´ˆê³¼]"

        if len(text_chunk.strip()) <= min_chunk_size:
            logger.warning(f"ìµœì†Œ ì²­í¬ í¬ê¸°ì— ë„ë‹¬í–ˆì§€ë§Œ ì—¬ì „íˆ ì˜¤ë¥˜ ë°œìƒ: {text_chunk[:50]}...")
            return f"[ë²ˆì—­ ì˜¤ë¥˜ë¡œ ì¸í•œ ì‹¤íŒ¨: {text_chunk[:30]}...]"

        logger.info(f"ğŸ“Š ì²­í¬ ë¶„í•  ì‹œë„ #{current_attempt} (ê¹Šì´: {current_attempt-1})")
        logger.info(f"   ğŸ“ ì›ë³¸ í¬ê¸°: {len(text_chunk)} ê¸€ì")
        logger.info(f"   ğŸ¯ ëª©í‘œ: ì •í™•íˆ 2ê°œ ì²­í¬ë¡œ ë¶„í•  (ì´ì§„ ë¶„í• )")

        # Strict ì´ì§„ ë¶„í•  (ì •í™•íˆ 2ê°œ ì²­í¬)
        sub_chunks = self.chunk_service.split_chunk_into_two_halves(
            text_chunk,
            target_size=len(text_chunk) // 2,
            min_chunk_ratio=0.3  # ë§ˆì§€ë§‰ ì²­í¬ê°€ 30% ë¯¸ë§Œì´ë©´ ë³‘í•©
        )
        
        if len(sub_chunks) <= 1:
            sub_chunks = self.chunk_service.split_chunk_by_sentences(
                text_chunk, max_sentences_per_chunk=1
            )
        
        if len(sub_chunks) <= 1:
            logger.error("ì²­í¬ ë¶„í•  ì‹¤íŒ¨. ë²ˆì—­ í¬ê¸°.")
            return f"[ë¶„í•  ë¶ˆê°€ëŠ¥í•œ ì˜¤ë¥˜ ë°œìƒ ì½˜í…ì¸ : {text_chunk[:30]}...]"
        
        logger.info(f"   ğŸ”„ {len(sub_chunks)}ê°œ ì„œë¸Œ ì²­í¬ë¥¼ ë³‘ë ¬ ì²˜ë¦¬í•©ë‹ˆë‹¤ (ë¹„ë™ê¸°).")
        
        # ë¹„ë™ê¸° ì‘ì—… ë˜í¼ í•¨ìˆ˜
        async def translate_sub_chunk_with_check(sub_chunk: str, idx: int) -> tuple[int, str]:
            """ê°œë³„ ì„œë¸Œ ì²­í¬ ë²ˆì—­ (ì·¨ì†Œ í™•ì¸ í¬í•¨)"""
            # ğŸ“ ì·¨ì†Œ í™•ì¸ 1: ì‘ì—… ì‹œì‘ ì „
            if self.stop_check_callback and self.stop_check_callback():
                raise asyncio.CancelledError(f"ì„œë¸Œ ì²­í¬ {idx+1} ë²ˆì—­ ì¤‘ë‹¨ ìš”ì²­ë¨ (ì‘ì—… ì‹œì‘ ì „)")
                        # âœ¨ ë°©ì–´ì  ì²´í¬í¬ì¸íŠ¸
            await asyncio.sleep(0)
            if not sub_chunk.strip():
                logger.warning(f"   âš ï¸ ì„œë¸Œ ì²­í¬ {idx+1}/{len(sub_chunks)} ë¹ˆ ì²­í¬ ê°ì§€. ìŠ¤í‚µ.")
                return (idx, "")
            
            try:
                # ğŸ“ ì·¨ì†Œ í™•ì¸ 2: API í˜¸ì¶œ ì§ì „
                if self.stop_check_callback and self.stop_check_callback():
                    raise asyncio.CancelledError(f"ì„œë¸Œ ì²­í¬ {idx+1} ë²ˆì—­ ì¤‘ë‹¨ ìš”ì²­ë¨ (API í˜¸ì¶œ ì§ì „)")
                
                translated = await self.translate_text_async(sub_chunk)
                logger.info(f"   âœ… ì„œë¸Œ ì²­í¬ {idx+1}/{len(sub_chunks)} ë²ˆì—­ ì™„ë£Œ")
                return (idx, translated)
                
            except asyncio.CancelledError:
                logger.info(f"   ğŸ›‘ ì„œë¸Œ ì²­í¬ {idx+1} ì·¨ì†Œë¨")
                raise
            except BtgTranslationException as e_sub:
                if "ì½˜í…ì¸  ì•ˆì „ ë¬¸ì œ" in str(e_sub) and current_attempt < max_split_attempts:
                    logger.warning(f"   ğŸ›¡ï¸ ì„œë¸Œ ì²­í¬ {idx+1} ì½˜í…ì¸  ì•ˆì „ ì˜¤ë¥˜. ì¬ê·€ ë¶„í•  ì‹œë„.")
                    recursive_result = await self._translate_with_recursive_splitting_async(
                        sub_chunk, max_split_attempts, min_chunk_size, current_attempt + 1
                    )
                    return (idx, recursive_result)
                else:
                    error_marker = f"[ì„œë¸Œ ì²­í¬ {idx+1} ë²ˆì—­ ì‹¤íŒ¨: {str(e_sub)[:50]}]"
                    logger.error(f"   âŒ ì„œë¸Œ ì²­í¬ {idx+1} ë²ˆì—­ ì‹¤íŒ¨: {str(e_sub)[:100]}")
                    return (idx, error_marker)
            except Exception as e_general:
                logger.error(f"   âŒ ì„œë¸Œ ì²­í¬ {idx+1} ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜: {e_general}")
                return (idx, f"[ì„œë¸Œ ì²­í¬ {idx+1} ë²ˆì—­ ì˜¤ë¥˜]")
        
        # ì‘ì—… ìƒì„± (ìˆœì°¨ì ìœ¼ë¡œ ì·¨ì†Œ í™•ì¸í•˜ë©° ìƒì„±)
        tasks = []
        for i, sub_chunk in enumerate(sub_chunks):
            # ğŸ“ ì·¨ì†Œ í™•ì¸: ì‘ì—… ìƒì„± ì „
            if self.stop_check_callback and self.stop_check_callback():
                logger.warning(f"ì¤‘ë‹¨ ìš”ì²­ ê°ì§€ë¨. {i}/{len(sub_chunks)}ê°œ ì„œë¸Œ ì²­í¬ ì‘ì—… ìƒì„± ì¤‘ ì¤‘ë‹¨.")
                break
            
            task = asyncio.create_task(translate_sub_chunk_with_check(sub_chunk, i))
            tasks.append(task)
        
        # ìƒì„±ëœ ì‘ì—…ë“¤ì„ ë³‘ë ¬ ì²˜ë¦¬
        results = []
        for task in tasks:
            try:
                idx, translated = await task
                results.append((idx, translated))
            except asyncio.CancelledError:
                logger.info("ì„œë¸Œ ì²­í¬ ë²ˆì—­ ì·¨ì†Œë¨. ë‚˜ë¨¸ì§€ ì‘ì—… ì·¨ì†Œ ì¤‘...")
                # ë‚˜ë¨¸ì§€ ì‘ì—…ë“¤ë„ ì·¨ì†Œ
                for remaining_task in tasks:
                    if not remaining_task.done():
                        remaining_task.cancel()
                raise BtgTranslationException("ì„œë¸Œ ì²­í¬ ë²ˆì—­ì´ ì·¨ì†Œë˜ì—ˆìŠµë‹ˆë‹¤.")
        
        # ê²°ê³¼ë¥¼ ì›ë˜ ìˆœì„œëŒ€ë¡œ ì •ë ¬í•˜ì—¬ ê²°í•©
        results.sort(key=lambda x: x[0])
        translated_parts = [text for _, text in results]
        
        logger.info(f"   ğŸ“Š ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ: {len(results)}/{len(sub_chunks)}ê°œ ì„œë¸Œ ì²­í¬ ì²˜ë¦¬ë¨")
        
        return "\n\n".join(translated_parts)

