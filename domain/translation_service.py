# translation_service.py
import time
import random
import re
import csv
from pathlib import Path
from typing import Dict, Any, Optional, List, Union
import os

try:
    from infrastructure.gemini_client import (
        GeminiClient,
        GeminiContentSafetyException,
        GeminiRateLimitException,
        GeminiApiException,
        GeminiInvalidRequestException,
        GeminiAllApiKeysExhaustedException 
    )
    from infrastructure.file_handler import read_json_file
    from infrastructure.logger_config import setup_logger
    from core.exceptions import BtgTranslationException, BtgApiClientException, BtgInvalidTranslationLengthException
    from utils.chunk_service import ChunkService
    # types ëª¨ë“ˆì€ gemini_clientì—ì„œ ì‚¬ìš©ë˜ë¯€ë¡œ, ì—¬ê¸°ì„œëŠ” ì§ì ‘ì ì¸ ì˜ì¡´ì„±ì´ ì—†ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤. # ë¡œì–´ë¶ -> ìš©ì–´ì§‘
    # ë§Œì•½ ì´ íŒŒì¼ ë‚´ì—ì„œ types.Part ë“±ì„ ì§ì ‘ ì‚¬ìš©í•œë‹¤ë©´, ì•„ë˜ì™€ ê°™ì´ ì„í¬íŠ¸ê°€ í•„ìš”í•©ë‹ˆë‹¤. # ë¡œì–´ë¶ -> ìš©ì–´ì§‘
    from google.genai import types as genai_types
    from core.dtos import GlossaryEntryDTO
except ImportError:
    from infrastructure.gemini_client import (  # type: ignore
        GeminiClient,
        GeminiContentSafetyException,
        GeminiRateLimitException,
        GeminiApiException,
        GeminiInvalidRequestException,
        GeminiAllApiKeysExhaustedException 
    )
    from infrastructure.file_handler import read_json_file  # type: ignore
    from infrastructure.logger_config import setup_logger  # type: ignore
    from core.exceptions import BtgTranslationException, BtgApiClientException, BtgInvalidTranslationLengthException  # type: ignore
    from utils.chunk_service import ChunkService  # type: ignore
    from core.dtos import GlossaryEntryDTO # type: ignore
    from google.genai import types as genai_types # Fallback import

logger = setup_logger(__name__)

def _format_glossary_for_prompt( # í•¨ìˆ˜ëª… ë³€ê²½
    glossary_entries: List[GlossaryEntryDTO], # DTOëŠ” GlossaryEntryDTO (ê²½ëŸ‰í™”ëœ ë²„ì „)
    max_entries: int,
    max_chars: int
) -> str:
    if not glossary_entries:
        return "ìš©ì–´ì§‘ ì»¨í…ìŠ¤íŠ¸ ì—†ìŒ" # ë©”ì‹œì§€ ë³€ê²½

    selected_entries_str = []
    current_chars = 0
    entries_count = 0

    # ë“±ì¥ íšŸìˆ˜ ë§ì€ ìˆœ, ê°™ìœ¼ë©´ í‚¤ì›Œë“œ ê°€ë‚˜ë‹¤ ìˆœìœ¼ë¡œ ì •ë ¬
    sorted_entries = sorted(glossary_entries, key=lambda x: (-x.occurrence_count, x.keyword.lower()))

    for entry in sorted_entries:
        if entries_count >= max_entries:
            break
        
        # í˜„ì¬ í•­ëª© ì¶”ê°€ ì‹œ ìµœëŒ€ ê¸€ì ìˆ˜ ì´ˆê³¼í•˜ë©´ ì¤‘ë‹¨ (ë‹¨, ìµœì†Œ 1ê°œëŠ” í¬í•¨ë˜ë„ë¡)
        # DTOì—ì„œ source_languageê°€ ì œê±°ë˜ì—ˆìœ¼ë¯€ë¡œ í•´ë‹¹ ë¶€ë¶„ í¬ë§·íŒ…ì—ì„œ ì œì™¸
        entry_str = (f"- {entry.keyword} "
                     f"-> {entry.translated_keyword} ({entry.target_language}) "
                     f"(ë“±ì¥: {entry.occurrence_count}íšŒ)")
        if current_chars + len(entry_str) > max_chars and entries_count > 0:
            break
        
        selected_entries_str.append(entry_str)
        current_chars += len(entry_str) + 1 # +1 for newline
        entries_count += 1

    if not selected_entries_str:
        return "ìš©ì–´ì§‘ ì»¨í…ìŠ¤íŠ¸ ì—†ìŒ (ì œí•œìœ¼ë¡œ ì¸í•´ ì„ íƒëœ í•­ëª© ì—†ìŒ)" # ë©”ì‹œì§€ ë³€ê²½
        
    return "\n".join(selected_entries_str)

class TranslationService:
    def __init__(self, gemini_client: GeminiClient, config: Dict[str, Any]):
        self.gemini_client = gemini_client
        self.config = config
        self.chunk_service = ChunkService()
        self.glossary_entries_for_injection: List[GlossaryEntryDTO] = [] # Renamed and type changed

        if self.config.get("enable_dynamic_glossary_injection", False): # Key changed
            self._load_glossary_data() # í•¨ìˆ˜ëª… ë³€ê²½
            logger.info("ë™ì  ìš©ì–´ì§‘ ì£¼ì… í™œì„±í™”ë¨. ìš©ì–´ì§‘ ë°ì´í„° ë¡œë“œ ì‹œë„.") # ë©”ì‹œì§€ ë³€ê²½
        else:
            logger.info("ë™ì  ìš©ì–´ì§‘ ì£¼ì… ë¹„í™œì„±í™”ë¨. ìš©ì–´ì§‘ ì»¨í…ìŠ¤íŠ¸ ì—†ì´ ë²ˆì—­í•©ë‹ˆë‹¤.") # ë©”ì‹œì§€ ë³€ê²½

    def _load_glossary_data(self): # í•¨ìˆ˜ëª… ë³€ê²½
        # í†µí•©ëœ ìš©ì–´ì§‘ ê²½ë¡œ ì‚¬ìš©
        lorebook_json_path_str = self.config.get("glossary_json_path")
        if lorebook_json_path_str and os.path.exists(lorebook_json_path_str):
            lorebook_json_path = Path(lorebook_json_path_str)
            try:
                raw_data = read_json_file(lorebook_json_path)
                if isinstance(raw_data, list):
                    for item_dict in raw_data:
                        if isinstance(item_dict, dict) and \
                           "keyword" in item_dict and \
                           "translated_keyword" in item_dict and \
                           "target_language" in item_dict:
                            try:
                                entry = GlossaryEntryDTO( # Explicitly use GlossaryEntryDTO
                                    keyword=item_dict.get("keyword", ""),
                                    translated_keyword=item_dict.get("translated_keyword", ""),
                                    target_language=item_dict.get("target_language", ""),
                                    occurrence_count=int(item_dict.get("occurrence_count", 0))
                                )
                                if all([entry.keyword, entry.translated_keyword, entry.source_language, entry.target_language]): # í•„ìˆ˜ í•„ë“œ í™•ì¸
                                    self.glossary_entries_for_injection.append(entry)
                                else:
                                    logger.warning(f"ê²½ëŸ‰ ìš©ì–´ì§‘ í•­ëª©ì— í•„ìˆ˜ í•„ë“œ ëˆ„ë½: {item_dict}")
                            except (TypeError, ValueError) as e_dto:
                                logger.warning(f"ìš©ì–´ì§‘ í•­ëª© DTO ë³€í™˜ ì¤‘ ì˜¤ë¥˜: {item_dict}, ì˜¤ë¥˜: {e_dto}") # ë©”ì‹œì§€ ë³€ê²½
                        else:
                            logger.warning(f"ì˜ëª»ëœ ìš©ì–´ì§‘ í•­ëª© í˜•ì‹ (ë”•ì…”ë„ˆë¦¬ê°€ ì•„ë‹ˆê±°ë‚˜ í•„ìˆ˜ í‚¤ 'keyword' ë˜ëŠ” 'description_ko' ëˆ„ë½) ê±´ë„ˆëœ€: {item_dict}") # ë©”ì‹œì§€ ë³€ê²½
                    logger.info(f"{len(self.glossary_entries_for_injection)}ê°œì˜ ìš©ì–´ì§‘ í•­ëª©ì„ ë¡œë“œí–ˆìŠµë‹ˆë‹¤: {lorebook_json_path}") # ë©”ì‹œì§€ ë³€ê²½
                else: # type: ignore
                    logger.error(f"ìš©ì–´ì§‘ JSON íŒŒì¼ì´ ë¦¬ìŠ¤íŠ¸ í˜•ì‹ì´ ì•„ë‹™ë‹ˆë‹¤: {lorebook_json_path}, íƒ€ì…: {type(raw_data)}") # ë©”ì‹œì§€ ë³€ê²½
            except Exception as e:
                logger.error(f"ìš©ì–´ì§‘ JSON íŒŒì¼ ì²˜ë¦¬ ì¤‘ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜ ({lorebook_json_path}): {e}", exc_info=True) # ë©”ì‹œì§€ ë³€ê²½
                self.glossary_entries_for_injection = []
        else:
            logger.info(f"ìš©ì–´ì§‘ JSON íŒŒì¼({lorebook_json_path_str})ì´ ì„¤ì •ë˜ì§€ ì•Šì•˜ê±°ë‚˜ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ë™ì  ì£¼ì…ì„ ìœ„í•´ ìš©ì–´ì§‘ì„ ì‚¬ìš©í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.") # ë©”ì‹œì§€ ë³€ê²½
            self.glossary_entries_for_injection = []

    def _construct_prompt(self, chunk_text: str) -> str:
        prompt_template = self.config.get("prompts", "Translate to Korean: {{slot}}")
        if isinstance(prompt_template, (list, tuple)):
            prompt_template = prompt_template[0] if prompt_template else "Translate to Korean: {{slot}}"

        final_prompt = prompt_template

        # Determine the source language for the current chunk to filter glossary entries
        config_source_lang = self.config.get("novel_language") # í†µí•©ëœ ì„¤ì • ì‚¬ìš©
        # Fallback language from config, with a hardcoded default if the config key itself is missing
        config_fallback_lang = self.config.get("novel_language_fallback", "ja") # í†µí•©ëœ í´ë°± ì„¤ì • ì‚¬ìš©

        # "auto" ëª¨ë“œì¼ ë•Œ, LLMì´ ì–¸ì–´ë¥¼ ê°ì§€í•˜ê³  ìš©ì–´ì§‘ì„ í•„í„°ë§í•˜ë„ë¡ í”„ë¡¬í”„íŠ¸ê°€ êµ¬ì„±ë©ë‹ˆë‹¤.
        # Python ë‹¨ì—ì„œ current_source_lang_for_translationì„ í™•ì •í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.
        # ë¡œê¹…ì´ë‚˜ íŠ¹ì • ì¡°ê±´ë¶€ ë¡œì§ì„ ìœ„í•´ì„  ì—¬ì „íˆ í•„ìš”í•  ìˆ˜ ìˆìœ¼ë‚˜, ìš©ì–´ì§‘ í•„í„°ë§ì€ LLMìœ¼ë¡œ ë„˜ì–´ê°‘ë‹ˆë‹¤.
        current_source_lang_for_glossary_filtering: Optional[str] = None

        if config_source_lang == "auto":
            logger.info(f"ë²ˆì—­ ì¶œë°œ ì–¸ì–´ ì„¤ì •: 'auto'. LLMì´ í”„ë¡¬í”„íŠ¸ ë‚´ì—ì„œ ì–¸ì–´ë¥¼ ê°ì§€í•˜ê³  ìš©ì–´ì§‘ì„ ì ìš©í•˜ë„ë¡ í•©ë‹ˆë‹¤.") # ë©”ì‹œì§€ ë³€ê²½
            # current_source_lang_for_glossary_filteringëŠ” Noneìœ¼ë¡œ ìœ ì§€í•˜ê±°ë‚˜ "auto"ë¡œ ì„¤ì •.
            # ìš©ì–´ì§‘ í•„í„°ë§ì€ LLMì˜ ì—­í• ì´ ë©ë‹ˆë‹¤.
        elif config_source_lang and isinstance(config_source_lang, str) and config_source_lang.strip(): # Specific language code provided
            current_source_lang_for_glossary_filtering = config_source_lang
            logger.info(f"ëª…ì‹œì  ë²ˆì—­ ì¶œë°œ ì–¸ì–´ '{current_source_lang_for_glossary_filtering}' ì‚¬ìš©. ìš©ì–´ì§‘ë„ ì´ ì–¸ì–´ ê¸°ì¤€ìœ¼ë¡œ í•„í„°ë§ë©ë‹ˆë‹¤.") # ë©”ì‹œì§€ ë³€ê²½
        else: # config_source_lang is None, empty string, or not "auto"
            current_source_lang_for_glossary_filtering = config_fallback_lang
            logger.warning(f"ë²ˆì—­ ì¶œë°œ ì–¸ì–´ê°€ ìœ íš¨í•˜ê²Œ ì„¤ì •ë˜ì§€ ì•Šì•˜ê±°ë‚˜ 'auto'ê°€ ì•„ë‹™ë‹ˆë‹¤. í´ë°± ì–¸ì–´ '{current_source_lang_for_glossary_filtering}'ë¥¼ ìš©ì–´ì§‘ í•„í„°ë§ì— ì‚¬ìš©.")

        # 1. Dynamic Glossary Injection
        if self.config.get("enable_dynamic_glossary_injection", False) and \
           self.glossary_entries_for_injection and \
           "{{glossary_context}}" in final_prompt: # Placeholder changed
            
            relevant_entries_for_chunk: List[GlossaryEntryDTO] = []
            chunk_text_lower = chunk_text.lower() # For case-insensitive keyword matching
            # ìµœì¢… ë²ˆì—­ ëª©í‘œ ì–¸ì–´ (ì˜ˆ: "ko")
            # ì´ ì„¤ì •ì€ config.json ë˜ëŠ” ë‹¤ë¥¸ ë°©ì‹ìœ¼ë¡œ ì œê³µë˜ì–´ì•¼ í•©ë‹ˆë‹¤.
            final_target_lang = self.config.get("target_translation_language", "ko").lower()

            if config_source_lang == "auto":
                # "auto" ëª¨ë“œ: ì²­í¬ì˜ ì–¸ì–´ëŠ” LLMì´ ê°ì§€.
                # ìš©ì–´ì§‘ í•­ëª©ì˜ target_languageê°€ ìµœì¢… ë²ˆì—­ ëª©í‘œ ì–¸ì–´ì™€ ì¼ì¹˜í•˜ëŠ” ê²ƒë§Œ ê³ ë ¤.
                # source_language í•„í„°ë§ì€ LLMì˜ ë¬¸ë§¥ ì´í•´ì— ë§¡ê¸°ê±°ë‚˜, ì—¬ê¸°ì„œ ê°„ë‹¨í•œ í‚¤ì›Œë“œ ë§¤ì¹­ë§Œ ìˆ˜í–‰.
                logger.info(f"ìë™ ì–¸ì–´ ê°ì§€ ëª¨ë“œ: ìš©ì–´ì§‘ì€ í‚¤ì›Œë“œ ì¼ì¹˜ ë° ìµœì¢… ëª©í‘œ ì–¸ì–´({final_target_lang}) ì¼ì¹˜ë¡œ í•„í„°ë§ í›„ LLMì— ì „ë‹¬.") # ë©”ì‹œì§€ ë³€ê²½
                for entry in self.glossary_entries_for_injection:
                    if entry.target_language.lower() == final_target_lang and \
                       entry.keyword.lower() in chunk_text_lower:
                        relevant_entries_for_chunk.append(entry)
            else:
                # ëª…ì‹œì  ì–¸ì–´ ì„¤ì • ëª¨ë“œ: Pythonì—ì„œ ì–¸ì–´ ë° í‚¤ì›Œë“œ ê¸°ë°˜ìœ¼ë¡œ í•„í„°ë§.
                logger.info(f"ëª…ì‹œì  ì–¸ì–´ ëª¨ë“œ ('{current_source_lang_for_glossary_filtering}'): ìš©ì–´ì§‘ì„ ì¶œë°œì–´/ë„ì°©ì–´ ë° í‚¤ì›Œë“œ ê¸°ì¤€ìœ¼ë¡œ í•„í„°ë§.") # ë©”ì‹œì§€ ë³€ê²½
                for entry in self.glossary_entries_for_injection:
                    # source_language í•„í„°ë§ ì œê±°. DTOì— í•´ë‹¹ í•„ë“œê°€ ì—†ìœ¼ë¯€ë¡œ.
                    if entry.target_language.lower() == final_target_lang and \
                       entry.keyword.lower() in chunk_text_lower:
                        relevant_entries_for_chunk.append(entry)
                    # source_language ê´€ë ¨ ë¡œê¹… ì œê±°
                    elif not (entry.target_language.lower() == final_target_lang): # target_language ë¶ˆì¼ì¹˜ ë¡œê¹…ì€ ìœ ì§€
                        logger.debug(f"ìš©ì–´ì§‘ í•­ëª© '{entry.keyword}' ê±´ë„ˆëœ€: ë„ì°© ì–¸ì–´ ë¶ˆì¼ì¹˜ (ìš©ì–´ì§‘TL: {entry.target_language}, ìµœì¢…TL: {final_target_lang}).")
                        continue
            
            logger.debug(f"í˜„ì¬ ì²­í¬ì— ëŒ€í•´ {len(relevant_entries_for_chunk)}ê°œì˜ ê´€ë ¨ ìš©ì–´ì§‘ í•­ëª© ë°œê²¬.") # ë©”ì‹œì§€ ë³€ê²½

            # 1.b. Format the relevant entries for the prompt
            max_entries = self.config.get("max_glossary_entries_per_chunk_injection", 3) # Key changed
            max_chars = self.config.get("max_glossary_chars_per_chunk_injection", 500) # Key changed
            
            formatted_glossary_context = _format_glossary_for_prompt( # í•¨ìˆ˜ëª… ë³€ê²½
                relevant_entries_for_chunk, max_entries, max_chars # Pass only relevant entries
            )
            
            # Check if actual content was formatted (not just "ì—†ìŒ" messages)
            if not formatted_glossary_context.startswith("ìš©ì–´ì§‘ ì»¨í…ìŠ¤íŠ¸ ì—†ìŒ"): # Check simplified
                logger.info(f"API ìš”ì²­ì— ë™ì  ìš©ì–´ì§‘ ì»¨í…ìŠ¤íŠ¸ ì£¼ì…ë¨. ë‚´ìš© ì¼ë¶€: {formatted_glossary_context[:100]}...") # ë©”ì‹œì§€ ë³€ê²½
                # ì£¼ì…ëœ ìš©ì–´ì§‘ í‚¤ì›Œë“œ ë¡œê¹…
                # ìƒì„¸ ë¡œê¹…ì€ _format_glossary_for_prompt ë‚´ë¶€ ë˜ëŠ” í˜¸ì¶œë¶€ì—ì„œ ì²˜ë¦¬ ê°€ëŠ¥
            else:
                logger.debug(f"ë™ì  ìš©ì–´ì§‘ ì£¼ì… ì‹œë„í–ˆìœ¼ë‚˜, ê´€ë ¨ í•­ëª© ì—†ê±°ë‚˜ ì œí•œìœ¼ë¡œ ì¸í•´ ì‹¤ì œ ì£¼ì… ë‚´ìš© ì—†ìŒ. ì‚¬ìš©ëœ ë©”ì‹œì§€: {formatted_glossary_context}")
            final_prompt = final_prompt.replace("{{glossary_context}}", formatted_glossary_context) # Placeholder changed
        else:
            if "{{glossary_context}}" in final_prompt: # Placeholder changed
                 final_prompt = final_prompt.replace("{{glossary_context}}", "ìš©ì–´ì§‘ ì»¨í…ìŠ¤íŠ¸ ì—†ìŒ (ì£¼ì… ë¹„í™œì„±í™” ë˜ëŠ” í•´ë‹¹ í•­ëª© ì—†ìŒ)") # Placeholder changed
                 logger.debug("ë™ì  ìš©ì–´ì§‘ ì£¼ì… ë¹„í™œì„±í™” ë˜ëŠ” í”Œë ˆì´ìŠ¤í™€ë” ë¶€ì¬ë¡œ 'ì»¨í…ìŠ¤íŠ¸ ì—†ìŒ' ë©”ì‹œì§€ ì‚¬ìš©.")
        
        # 3. Main content slot - This should be done *after* all other placeholders are processed.
        final_prompt = final_prompt.replace("{{slot}}", chunk_text)
        
        return final_prompt

    def _validate_translation_length(self, original_text: str, translated_text: str):
        """
        ë²ˆì—­ëœ í…ìŠ¤íŠ¸ì˜ ê¸¸ì´ê°€ ì›ë³¸ê³¼ ë¹„êµí•˜ì—¬ ì ì ˆí•œì§€ ê²€ì‚¬í•©ë‹ˆë‹¤.
        ì§€ë‚˜ì¹˜ê²Œ ì§§ê±°ë‚˜ ê¸¸ ê²½ìš° BtgInvalidTranslationLengthExceptionì„ ë°œìƒì‹œí‚µë‹ˆë‹¤.
        """
        original_len = len(original_text.strip())
        translated_len = len(translated_text.strip())

        if original_len == 0 and translated_len > 0:
            logger.warning(f"ì›ë³¸ í…ìŠ¤íŠ¸ëŠ” ë¹„ì–´ìˆìœ¼ë‚˜ ë²ˆì—­ ê²°ê³¼ëŠ” ë‚´ìš©ì´ ìˆìŠµë‹ˆë‹¤. ì›ë³¸ ê¸¸ì´: {original_len}, ë²ˆì—­ ê¸¸ì´: {translated_len}")
            return

        if original_len > 0 and translated_len == 0:
            # ì´ ê²½ìš°ëŠ” translate_text ë©”ì„œë“œì—ì„œ ì´ë¯¸ GeminiContentSafetyException ë“±ìœ¼ë¡œ ì²˜ë¦¬ë  ìˆ˜ ìˆìŒ
            logger.warning(f"ì›ë³¸ í…ìŠ¤íŠ¸ëŠ” ë‚´ìš©ì´ ìˆìœ¼ë‚˜ ë²ˆì—­ ê²°ê³¼ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤. ì›ë³¸ ê¸¸ì´: {original_len}, ë²ˆì—­ ê¸¸ì´: {translated_len}")
            # translate_textì—ì„œ ì´ë¯¸ ì˜ˆì™¸ ì²˜ë¦¬ë˜ë¯€ë¡œ ì—¬ê¸°ì„œëŠ” ë³„ë„ ì˜ˆì™¸ ë°œìƒ ì•ˆ í•¨ (ë˜ëŠ” ë‹¤ë¥¸ ì˜ˆì™¸ë¡œ ë˜í•‘ ê°€ëŠ¥)
            return

        if original_len == 0 and translated_len == 0:
            return # ë‘˜ ë‹¤ ë¹„ì–´ìˆìœ¼ë©´ ì •ìƒ

        min_length_ratio = self.config.get("translation_min_length_ratio", 0.15)
        max_length_ratio = self.config.get("translation_max_length_ratio", 2.5)

        ratio = translated_len / original_len

        if ratio < min_length_ratio:
            message = (
                f"ë²ˆì—­ëœ í…ìŠ¤íŠ¸ì˜ ê¸¸ì´ê°€ ì›ë³¸ì— ë¹„í•´ ë„ˆë¬´ ì§§ìŠµë‹ˆë‹¤. "
                f"ì›ë³¸ ê¸¸ì´: {original_len}, ë²ˆì—­ ê¸¸ì´: {translated_len} (ë¹„ìœ¨: {ratio:.2f}, ìµœì†Œ í—ˆìš© ë¹„ìœ¨: {min_length_ratio}). "
                f"ì›ë³¸ ë¯¸ë¦¬ë³´ê¸°: '{original_text[:50]}...', ë²ˆì—­ ë¯¸ë¦¬ë³´ê¸°: '{translated_text[:50]}...'"
            )
            logger.error(message)
            raise BtgInvalidTranslationLengthException(message)

        if ratio > max_length_ratio:
            message = (
                f"ë²ˆì—­ëœ í…ìŠ¤íŠ¸ì˜ ê¸¸ì´ê°€ ì›ë³¸ì— ë¹„í•´ ë„ˆë¬´ ê¹ë‹ˆë‹¤. "
                f"ì›ë³¸ ê¸¸ì´: {original_len}, ë²ˆì—­ ê¸¸ì´: {translated_len} (ë¹„ìœ¨: {ratio:.2f}, ìµœëŒ€ í—ˆìš© ë¹„ìœ¨: {max_length_ratio}). "
                f"ì›ë³¸ ë¯¸ë¦¬ë³´ê¸°: '{original_text[:50]}...', ë²ˆì—­ ë¯¸ë¦¬ë³´ê¸°: '{translated_text[:50]}...'"
            )
            logger.error(message)
            raise BtgInvalidTranslationLengthException(message)

        logger.debug(f"ë²ˆì—­ ê¸¸ì´ ê²€ì¦ í†µê³¼: ì›ë³¸ ê¸¸ì´ {original_len}, ë²ˆì—­ ê¸¸ì´ {translated_len} (ë¹„ìœ¨: {ratio:.2f})")

    def translate_text(self, text_chunk: str, stream: bool = False) -> str:
        """
        ì£¼ì–´ì§„ í…ìŠ¤íŠ¸ ì²­í¬ë¥¼ ë²ˆì—­í•©ë‹ˆë‹¤.
        í”„ë¦¬í•„ ëª¨ë“œ ì‚¬ìš© ì‹œ prefill_system_instructionê³¼ prefill_cached_historyë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.
        chat_prompt (user prompt)ëŠ” _construct_promptë¥¼ í†µí•´ êµ¬ì„±ë©ë‹ˆë‹¤.
        """
        if not text_chunk.strip():
            logger.debug("Translate_text: ì…ë ¥ í…ìŠ¤íŠ¸ê°€ ë¹„ì–´ ìˆì–´ ë¹ˆ ë¬¸ìì—´ ë°˜í™˜.")
            return ""
        
        api_prompt_for_gemini_client: Union[str, List[genai_types.Content]] # ë³€ê²½: List[Content] ì‚¬ìš©
        api_system_instruction: Optional[str] # ë³€ê²½: Optional[str]

        if self.config.get("enable_prefill_translation", False):
            logger.info("í”„ë¦¬í•„ ë²ˆì—­ ëª¨ë“œ í™œì„±í™”ë¨.")
            api_system_instruction = self.config.get("prefill_system_instruction", "")
            prefill_cached_history_raw = self.config.get("prefill_cached_history", [])

            # prefill_cached_history_rawê°€ ì˜¬ë°”ë¥¸ í˜•ì‹ì¸ì§€ í™•ì¸ (ë¦¬ìŠ¤íŠ¸ì´ë©°, ê° í•­ëª©ì´ ë”•ì…”ë„ˆë¦¬ì¸ì§€)
            if not isinstance(prefill_cached_history_raw, list):
                logger.warning(f"ì˜ëª»ëœ prefill_cached_history í˜•ì‹ ({type(prefill_cached_history_raw)}). ë¹ˆ ë¦¬ìŠ¤íŠ¸ë¡œ ëŒ€ì²´í•©ë‹ˆë‹¤.")
                prefill_cached_history = []
            else:
                prefill_cached_history = []
                for item in prefill_cached_history_raw:
                    if isinstance(item, dict) and "role" in item and "parts" in item:
                        raw_parts = item.get("parts")
                        # parts ë‚´ë¶€ì˜ ë¬¸ìì—´ë“¤ì„ Part ê°ì²´ë¡œ ë³€í™˜
                        sdk_parts = []
                        if isinstance(raw_parts, list):
                            for part_item in raw_parts:
                                if isinstance(part_item, str):
                                    sdk_parts.append(genai_types.Part.from_text(text=part_item)) # ëª…ì‹œì ìœ¼ë¡œ text= ì‚¬ìš©
                                elif isinstance(part_item, genai_types.Part): # ì´ë¯¸ Part ê°ì²´ì¸ ê²½ìš°
                                    sdk_parts.append(part_item)
                        if sdk_parts: # ìœ íš¨í•œ partê°€ ìˆëŠ” ê²½ìš°ì—ë§Œ ì¶”ê°€
                            prefill_cached_history.append(genai_types.Content(role=item["role"], parts=sdk_parts))
                    else:
                        logger.warning(f"ì˜ëª»ëœ prefill_cached_history í•­ëª© ê±´ë„ˆëœ€: {item}")
            
            # í˜„ì¬ ì²­í¬ì— ëŒ€í•œ ì‚¬ìš©ì í”„ë¡¬í”„íŠ¸ (ê¸°ì¡´ _construct_prompt ê²°ê³¼)
            current_chunk_user_prompt_str = self._construct_prompt(text_chunk)
            
            # APIì— ì „ë‹¬í•  contents êµ¬ì„±: List[Content] í˜•íƒœ
            api_prompt_for_gemini_client = list(prefill_cached_history) # ë³µì‚¬í•´ì„œ ì‚¬ìš©
            api_prompt_for_gemini_client.append(
                genai_types.Content(role="user", parts=[genai_types.Part.from_text(text=str(current_chunk_user_prompt_str))]) # ëª…ì‹œì ìœ¼ë¡œ text= ì‚¬ìš© ë° str() ë³€í™˜
            )
            logger.debug(f"í”„ë¦¬í•„ ëª¨ë“œ: ì‹œìŠ¤í…œ ì§€ì¹¨='{api_system_instruction[:50]}...', contents ê°œìˆ˜={len(api_prompt_for_gemini_client)}")

        else:
            logger.info("í‘œì¤€ ë²ˆì—­ ëª¨ë“œ í™œì„±í™”ë¨.")
            api_system_instruction = None # í”„ë¦¬í•„ ë¹„í™œì„±í™” ì‹œ ì‹œìŠ¤í…œ ì§€ì¹¨ ì—†ìŒ
            api_prompt_for_gemini_client = self._construct_prompt(text_chunk) # ë¬¸ìì—´
            logger.debug(f"í‘œì¤€ ëª¨ë“œ: ì‹œìŠ¤í…œ ì§€ì¹¨ ì—†ìŒ, í”„ë¡¬í”„íŠ¸ ê¸¸ì´={len(api_prompt_for_gemini_client)}")

        try:
            logger.debug(f"Gemini API í˜¸ì¶œ ì‹œì‘. ëª¨ë¸: {self.config.get('model_name')}")
            
            translated_text_from_api = self.gemini_client.generate_text( # Renamed variable
                prompt=api_prompt_for_gemini_client, # Union[str, List[Dict]]
                model_name=self.config.get("model_name", "gemini-2.0-flash"),
                generation_config_dict={
                    "temperature": self.config.get("temperature", 0.7),
                    "top_p": self.config.get("top_p", 0.9)
                },
                system_instruction_text=api_system_instruction, # Optional[str] ì „ë‹¬
                stream=stream 
            )

            if translated_text_from_api is None:
                logger.error("GeminiClient.generate_textê°€ Noneì„ ë°˜í™˜í–ˆìŠµë‹ˆë‹¤.")
                raise GeminiContentSafetyException("APIë¡œë¶€í„° ì‘ë‹µì„ ë°›ì§€ ëª»í–ˆìŠµë‹ˆë‹¤ (None ë°˜í™˜).")

            if not translated_text_from_api.strip() and text_chunk.strip():
                logger.warning(f"APIê°€ ë¹„ì–´ìˆì§€ ì•Šì€ ì…ë ¥ì— ëŒ€í•´ ë¹ˆ ë¬¸ìì—´ì„ ë°˜í™˜í–ˆìŠµë‹ˆë‹¤. ì›ë³¸: '{text_chunk[:100]}...'")
                raise GeminiContentSafetyException("APIê°€ ë¹„ì–´ìˆì§€ ì•Šì€ ì…ë ¥ì— ëŒ€í•´ ë¹ˆ ë²ˆì—­ ê²°ê³¼ë¥¼ ë°˜í™˜í–ˆìŠµë‹ˆë‹¤.")

            logger.debug(f"Gemini API í˜¸ì¶œ ì„±ê³µ. ë²ˆì—­ëœ í…ìŠ¤íŠ¸ (ì¼ë¶€): {translated_text_from_api[:100]}...")
            
            # ë²ˆì—­ í›„ ê¸¸ì´ ê²€ì¦
            self._validate_translation_length(text_chunk, translated_text_from_api)
            
            # ë¬¸ì¥ë¶€í˜¸ ì¼ê´€ì„± ê²€ì‚¬ ë¡œì§ ì œê±°
        
        except GeminiContentSafetyException as e_safety:
            logger.warning(f"ì½˜í…ì¸  ì•ˆì „ ë¬¸ì œë¡œ ë²ˆì—­ ì‹¤íŒ¨: {e_safety}")
            # ì½˜í…ì¸  ì•ˆì „ ë¬¸ì œ ë°œìƒ ì‹œ, ë¶„í•  ì¬ì‹œë„ ë¡œì§ì„ í˜¸ì¶œí•˜ë„ë¡ ë³€ê²½
            # translate_text_with_content_safety_retryê°€ ì´ ì˜ˆì™¸ë¥¼ ì²˜ë¦¬í•˜ë„ë¡ í•¨
            raise BtgTranslationException(f"ì½˜í…ì¸  ì•ˆì „ ë¬¸ì œë¡œ ë²ˆì—­í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ({e_safety})", original_exception=e_safety) from e_safety
        except BtgInvalidTranslationLengthException: # ìƒˆë¡œ ì¶”ê°€ëœ ì˜ˆì™¸ ì²˜ë¦¬
            raise # ì´ë¯¸ ë¡œê¹…ë˜ì—ˆìœ¼ë¯€ë¡œ ê·¸ëŒ€ë¡œ ë‹¤ì‹œ ë°œìƒì‹œì¼œ ìƒìœ„ì—ì„œ ì²˜ë¦¬í•˜ë„ë¡ í•¨
        except GeminiAllApiKeysExhaustedException as e_keys:
            logger.error(f"API í‚¤ íšŒì „ ì‹¤íŒ¨: ëª¨ë“  API í‚¤ ì†Œì§„ ë˜ëŠ” ìœ íš¨í•˜ì§€ ì•ŠìŒ. ì›ë³¸ ì˜¤ë¥˜: {e_keys}")
            raise BtgApiClientException(f"ëª¨ë“  API í‚¤ë¥¼ ì‚¬ìš©í–ˆìœ¼ë‚˜ ìš”ì²­ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. API í‚¤ ì„¤ì •ì„ í™•ì¸í•˜ì„¸ìš”. ({e_keys})", original_exception=e_keys) from e_keys
        except GeminiRateLimitException as e_rate:
            logger.error(f"API ì‚¬ìš©ëŸ‰ ì œí•œ ì´ˆê³¼ (í‚¤ íšŒì „ í›„ì—ë„ ë°œìƒ): {e_rate}")
            raise BtgApiClientException(f"API ì‚¬ìš©ëŸ‰ ì œí•œì„ ì´ˆê³¼í–ˆìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”. ({e_rate})", original_exception=e_rate) from e_rate
        except GeminiInvalidRequestException as e_invalid:
            logger.error(f"ì˜ëª»ëœ API ìš”ì²­: {e_invalid}")
            raise BtgApiClientException(f"ì˜ëª»ëœ API ìš”ì²­ì…ë‹ˆë‹¤: {e_invalid}", original_exception=e_invalid) from e_invalid
        except GeminiApiException as e_api: # Catches other general API errors from GeminiClient
            logger.error(f"Gemini API í˜¸ì¶œ ì¤‘ ì¼ë°˜ ì˜¤ë¥˜ ë°œìƒ: {e_api}")
            raise BtgApiClientException(f"API í˜¸ì¶œ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e_api}", original_exception=e_api) from e_api
        # BtgTranslationException for empty string is now caught here if raised from above
        except BtgTranslationException: # Re-raise if it's our specific empty string exception
            raise
        except Exception as e: # Catch-all for other unexpected errors
            logger.error(f"ë²ˆì—­ ì¤‘ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜ ë°œìƒ: {e}", exc_info=True)
            raise BtgTranslationException(f"ë²ˆì—­ ì¤‘ ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}", original_exception=e) from e
        
        return translated_text_from_api.strip() # Return the stripped translated text
    
    def translate_text_with_content_safety_retry(
        self, 
        text_chunk: str, 
        max_split_attempts: int = 3,
        min_chunk_size: int = 100
    ) -> str:
        """
        ì½˜í…ì¸  ì•ˆì „ ì˜¤ë¥˜ ë°œìƒì‹œ ì²­í¬ë¥¼ ë¶„í• í•˜ì—¬ ì¬ì‹œë„í•˜ëŠ” ë²ˆì—­ ë©”ì„œë“œ
        
        Args:
            text_chunk: ë²ˆì—­í•  í…ìŠ¤íŠ¸
            max_split_attempts: ìµœëŒ€ ë¶„í•  ì‹œë„ íšŸìˆ˜
            min_chunk_size: ìµœì†Œ ì²­í¬ í¬ê¸°
            
        Returns:
            ë²ˆì—­ëœ í…ìŠ¤íŠ¸ (ì‹¤íŒ¨í•œ ë¶€ë¶„ì€ ì˜¤ë¥˜ ë©”ì‹œì§€ë¡œ ëŒ€ì²´)
        """
        try:
            # 1ì°¨ ì‹œë„: ì „ì²´ ì²­í¬ ë²ˆì—­
            return self.translate_text(text_chunk)
        except BtgTranslationException as e:
            # ì½˜í…ì¸  ì•ˆì „ ë¬¸ì œ ë˜ëŠ” ë¬¸ì¥ë¶€í˜¸ ë¶ˆì¼ì¹˜ ë¬¸ì œê°€ ì•„ë‹Œ ê²½ìš°, ê·¸ëŒ€ë¡œ ì˜ˆì™¸ ë°œìƒ
            # BtgInvalidTranslationLengthExceptionë„ ì¬ì‹œë„ ëŒ€ìƒì— í¬í•¨
            if not ("ì½˜í…ì¸  ì•ˆì „ ë¬¸ì œ" in str(e) or \
                    isinstance(e, BtgInvalidTranslationLengthException)):
                raise e
            
            error_type_for_log = "ì½˜í…ì¸  ì•ˆì „ ë¬¸ì œ" if "ì½˜í…ì¸  ì•ˆì „ ë¬¸ì œ" in str(e) else "ë²ˆì—­ ê¸¸ì´ ë¬¸ì œ"
            logger.warning(f"{error_type_for_log} ê°ì§€. ì²­í¬ ë¶„í•  ì¬ì‹œë„ ì‹œì‘: {str(e)}")
            return self._translate_with_recursive_splitting(
                text_chunk, max_split_attempts, min_chunk_size, current_attempt=1
            )

    def _translate_with_recursive_splitting(
        self,
        text_chunk: str,
        max_split_attempts: int,
        min_chunk_size: int,
        current_attempt: int = 1
    ) -> str:
    
        if current_attempt > max_split_attempts:
            logger.error(f"ìµœëŒ€ ë¶„í•  ì‹œë„ íšŸìˆ˜({max_split_attempts})ì— ë„ë‹¬. ë²ˆì—­ ì‹¤íŒ¨.")
            return f"[ë²ˆì—­ ì˜¤ë¥˜ë¡œ ì¸í•œ ì‹¤íŒ¨: ìµœëŒ€ ë¶„í•  ì‹œë„ ì´ˆê³¼]" # ë©”ì‹œì§€ ì¼ë°˜í™”

        if len(text_chunk.strip()) <= min_chunk_size:
            logger.warning(f"ìµœì†Œ ì²­í¬ í¬ê¸°ì— ë„ë‹¬í–ˆì§€ë§Œ ì—¬ì „íˆ ì˜¤ë¥˜ ë°œìƒ: {text_chunk[:50]}...")
            return f"[ë²ˆì—­ ì˜¤ë¥˜ë¡œ ì¸í•œ ì‹¤íŒ¨: {text_chunk[:30]}...]" # ë©”ì‹œì§€ ì¼ë°˜í™”

        logger.info(f"ğŸ“Š ì²­í¬ ë¶„í•  ì‹œë„ #{current_attempt} (ê¹Šì´: {current_attempt-1})")
        logger.info(f"   ğŸ“ ì›ë³¸ í¬ê¸°: {len(text_chunk)} ê¸€ì")
        logger.info(f"   ğŸ¯ ëª©í‘œ í¬ê¸°: {len(text_chunk) // 2} ê¸€ì")
        logger.info(f"   ğŸ“ ë‚´ìš© ë¯¸ë¦¬ë³´ê¸°: {text_chunk[:100].replace(chr(10), ' ')}...")

        
        # 1ë‹¨ê³„: í¬ê¸° ê¸°ë°˜ ë¶„í• 
        sub_chunks = self.chunk_service.split_chunk_recursively(
            text_chunk,
            target_size=len(text_chunk) // 2,
            min_chunk_size=min_chunk_size,
            max_split_depth=1,  # 1ë‹¨ê³„ë§Œ ë¶„í• 
            current_depth=0
        )
        
        # ë¶„í• ì´ ì•ˆëœ ê²½ìš° ë¬¸ì¥ ê¸°ë°˜ ë¶„í•  ì‹œë„
        if len(sub_chunks) <= 1:
            logger.info("í¬ê¸° ê¸°ë°˜ ë¶„í•  ì‹¤íŒ¨. ë¬¸ì¥ ê¸°ë°˜ ë¶„í•  ì‹œë„.")
            sub_chunks = self.chunk_service.split_chunk_by_sentences(
                text_chunk, max_sentences_per_chunk=1
            )
        
        if len(sub_chunks) <= 1:
            logger.error("ì²­í¬ ë¶„í•  ì‹¤íŒ¨. ë²ˆì—­ í¬ê¸°.")
            return f"[ë¶„í•  ë¶ˆê°€ëŠ¥í•œ ì˜¤ë¥˜ ë°œìƒ ì½˜í…ì¸ : {text_chunk[:30]}...]" # ë©”ì‹œì§€ ì¼ë°˜í™”
        
        # ê° ì„œë¸Œ ì²­í¬ ê°œë³„ ë²ˆì—­ ì‹œë„
        translated_parts = []
        total_sub_chunks = len(sub_chunks)
        successful_sub_chunks = 0
        failed_sub_chunks = 0
        
        logger.info(f"ğŸ”„ ë¶„í•  ì™„ë£Œ: {total_sub_chunks}ê°œ ì„œë¸Œ ì²­í¬ ìƒì„±")
        
        for i, sub_chunk in enumerate(sub_chunks):
            sub_chunk_info = f"ì„œë¸Œ ì²­í¬ {i+1}/{total_sub_chunks}"
            sub_chunk_size = len(sub_chunk.strip())
            sub_chunk_preview = sub_chunk.strip()[:50].replace('\n', ' ') + '...'
            
            logger.info(f"   ğŸš€ {sub_chunk_info} ë²ˆì—­ ì‹œì‘")
            logger.debug(f"      ğŸ“ í¬ê¸°: {sub_chunk_size} ê¸€ì")
            logger.debug(f"      ğŸ“ ë‚´ìš©: {sub_chunk_preview}")
            
            start_time = time.time()
            
            try:
                # ì¬ê·€ ë¶„í•  ì‹œ ìŠ¤íŠ¸ë¦¬ë° ì‚¬ìš©
                translated_part = self.translate_text(sub_chunk.strip(), stream=True)
                processing_time = time.time() - start_time
                
                translated_parts.append(translated_part)
                successful_sub_chunks += 1
                
                logger.info(f"   âœ… {sub_chunk_info} ë²ˆì—­ ì„±ê³µ (ì†Œìš”: {processing_time:.2f}ì´ˆ, ê¹Šì´: {current_attempt-1})")
                logger.debug(f"      ğŸ“Š ê²°ê³¼ ê¸¸ì´: {len(translated_part)} ê¸€ì")
                logger.debug(f"      ğŸ“ˆ ì§„í–‰ë¥ : {(i+1)/total_sub_chunks*100:.1f}% ({i+1}/{total_sub_chunks})")
                logger.debug(f"      ğŸ“ ë²ˆì—­ëœ ë‚´ìš© (ì¼ë¶€): {translated_part[:50].replace(chr(10), ' ')}...")
                
            except BtgTranslationException as sub_e:
                processing_time = time.time() - start_time
                
                # ì½˜í…ì¸  ì•ˆì „ ë¬¸ì œ ë˜ëŠ” ë¬¸ì¥ë¶€í˜¸ ë¶ˆì¼ì¹˜ ë¬¸ì œì¸ ê²½ìš° ì¬ê·€ ì‹œë„
                if "ì½˜í…ì¸  ì•ˆì „ ë¬¸ì œ" in str(sub_e) or \
                   isinstance(sub_e, BtgInvalidTranslationLengthException):
                    error_type_for_log_sub = "ì½˜í…ì¸  ì•ˆì „ ë¬¸ì œ" if "ì½˜í…ì¸  ì•ˆì „ ë¬¸ì œ" in str(sub_e) else "ë²ˆì—­ ê¸¸ì´ ë¬¸ì œ"
                    logger.warning(f"   ğŸ›¡ï¸ {sub_chunk_info} {error_type_for_log_sub} ë°œìƒ (ì†Œìš”: {processing_time:.2f}ì´ˆ)") # ë¬¸ì¥ë¶€í˜¸ ê´€ë ¨ ë©”ì‹œì§€ ì œê±°
                    logger.info(f"   ğŸ”„ ì¬ê·€ ë¶„í•  ì‹œë„ (ê¹Šì´: {current_attempt} â†’ {current_attempt+1})")
                    
                    # ì¬ê·€ì ìœ¼ë¡œ ë” ì‘ê²Œ ë¶„í•  ì‹œë„
                    recursive_result = self._translate_with_recursive_splitting(
                        sub_chunk, max_split_attempts, min_chunk_size, current_attempt + 1
                    )
                    translated_parts.append(recursive_result)
                    if "[ë²ˆì—­ ì˜¤ë¥˜ë¡œ ì¸í•œ ì‹¤íŒ¨" in recursive_result or "[ë¶„í•  ë¶ˆê°€ëŠ¥í•œ ì˜¤ë¥˜ ë°œìƒ ì½˜í…ì¸ " in recursive_result: # ì˜¤ë¥˜ ë©”ì‹œì§€ í™•ì¸ ê°•í™”
                        failed_sub_chunks += 1
                        logger.warning(f"   âŒ {sub_chunk_info} ìµœì¢… ì‹¤íŒ¨ (ì¬ê·€ ë¶„í•  í›„ì—ë„ ê²€ì—´ë¨)")
                    else:
                        successful_sub_chunks += 1
                        logger.info(f"   âœ… {sub_chunk_info} ì¬ê·€ ë¶„í•  í›„ ì„±ê³µ")
                else:
                    # ë‹¤ë¥¸ ë²ˆì—­ ì˜¤ë¥˜ì¸ ê²½ìš°
                    failed_sub_chunks += 1
                    
                    # APIë¡œë¶€í„° ë°›ì€ ì‹¤ì œ ì˜¤ë¥˜ ë©”ì‹œì§€ì— ê°€ê¹Œìš´ ë‚´ìš©ì„ ì¶”ì¶œ ì‹œë„
                    actual_api_error_str = str(sub_e) # ê¸°ë³¸ê°’: ì¡íŒ ì˜ˆì™¸ì˜ ì „ì²´ ë©”ì‹œì§€
                    if hasattr(sub_e, 'original_exception') and sub_e.original_exception:
                        orig_exc = sub_e.original_exception
                        # BtgApiClientException -> Gemini*Exception ì²´ì¸ í™•ì¸
                        if isinstance(orig_exc, BtgApiClientException) and \
                           hasattr(orig_exc, 'original_exception') and orig_exc.original_exception:
                            # orig_exc.original_exceptionì´ Gemini*Exception ê°ì²´ì„
                            actual_api_error_str = str(orig_exc.original_exception)
                        else:
                            # ì§ì ‘ì ì¸ ì›ì¸ ì˜ˆì™¸ì˜ ë©”ì‹œì§€ ì‚¬ìš©
                            actual_api_error_str = str(orig_exc)
                    
                    logger.error(f"   âŒ {sub_chunk_info} ë²ˆì—­ ì‹¤íŒ¨ (ì†Œìš”: {processing_time:.2f}ì´ˆ, ì˜ˆì™¸: {type(sub_e).__name__})")
                    logger.error(f"     API ì‹¤ì œ ì˜¤ë¥˜ ì‘ë‹µ (ì¶”ì •): {actual_api_error_str}") # ìƒì„¸ ì˜¤ë¥˜ ë¡œê¹…
                    translated_parts.append(f"[ë²ˆì—­ ì‹¤íŒ¨: {str(sub_e)[:100]}]") # ë²ˆì—­ ê²°ê³¼ì—ëŠ” ê°„ëµí•œ ì˜¤ë¥˜ ë©”ì‹œì§€ ìœ ì§€
                
                logger.debug(f"      ğŸ“ˆ ì§„í–‰ë¥ : {(i+1)/total_sub_chunks*100:.1f}% ({i+1}/{total_sub_chunks})")

        
        # ë²ˆì—­ëœ ë¶€ë¶„ë“¤ì„ ê²°í•©
        final_result = " ".join(translated_parts)
        
        # ë¶„í•  ë²ˆì—­ ì™„ë£Œ ìš”ì•½
        logger.info(f"ğŸ“‹ ë¶„í•  ë²ˆì—­ ì™„ë£Œ ìš”ì•½ (ê¹Šì´: {current_attempt-1})")
        logger.info(f"   ğŸ“Š ì´ ì„œë¸Œ ì²­í¬: {total_sub_chunks}ê°œ")
        logger.info(f"   âœ… ì„±ê³µ: {successful_sub_chunks}ê°œ")
        logger.info(f"   âŒ ì‹¤íŒ¨: {failed_sub_chunks}ê°œ")
        logger.info(f"   ğŸ“ ìµœì¢… ê²°ê³¼ ê¸¸ì´: {len(final_result)} ê¸€ì")
        
        if successful_sub_chunks > 0:
            success_rate = (successful_sub_chunks / total_sub_chunks) * 100
            logger.info(f"   ğŸ“ˆ ì„±ê³µë¥ : {success_rate:.1f}%")
        
        return final_result
    




if __name__ == '__main__':
    # MockGeminiClientì—ì„œ typesë¥¼ ì‚¬ìš©í•˜ë¯€ë¡œ, ì´ ë¸”ë¡ ë‚´ì—ì„œ ì„í¬íŠ¸í•©ë‹ˆë‹¤.
    from google.genai import types as genai_types # Ensure types is imported for hints

    print("--- TranslationService í…ŒìŠ¤íŠ¸ ---")
    class MockGeminiClient(GeminiClient):
        def __init__(self, auth_credentials, project=None, location=None, requests_per_minute: Optional[int] = None):
            try:
                super().__init__(auth_credentials=auth_credentials, project=project, location=location, requests_per_minute=requests_per_minute)
            except Exception as e:
                print(f"Warning: MockGeminiClient super().__init__ failed: {e}. This might be okay for some mock scenarios.")
                # If super init fails (e.g. dummy API key validation),
                # the mock might still function if it overrides all necessary methods
                # and doesn't rely on base class state initialized by __init__.
                # For Pylance, inheritance is the main fix.

            self.mock_auth_credentials = auth_credentials
            self.current_model_name_for_test: Optional[str] = None
            self.mock_api_keys_list: List[str] = []
            self.mock_current_api_key: Optional[str] = None

            if isinstance(auth_credentials, list):
                self.mock_api_keys_list = auth_credentials
                if self.mock_api_keys_list: self.mock_current_api_key = self.mock_api_keys_list[0]
            elif isinstance(auth_credentials, str) and not auth_credentials.startswith('{'): # Assuming API key string
                self.mock_api_keys_list = [auth_credentials]
                self.mock_current_api_key = auth_credentials
            print(f"MockGeminiClient initialized. Mock API Keys: {self.mock_api_keys_list}, Mock Current Key: {self.mock_current_api_key}")

        def generate_text(
            self,
            prompt: Union[str, List[Union[str, genai_types.Part]]],
            model_name: str,
            generation_config_dict: Optional[Dict[str, Any]] = None,
            safety_settings_list_of_dicts: Optional[List[Dict[str, Any]]] = None,
            system_instruction_text: Optional[str] = None,
            max_retries: int = 5,
            initial_backoff: float = 2.0,
            max_backoff: float = 60.0,
            stream: bool = False
        ) -> Optional[Union[str, Any]]:
            self.current_model_name_for_test = model_name

            prompt_text_for_mock = ""
            if isinstance(prompt, str):
                prompt_text_for_mock = prompt
            elif isinstance(prompt, list):
                temp_parts = []
                for item in prompt:
                    if isinstance(item, str):
                        temp_parts.append(item)
                    elif hasattr(item, 'text'): # Duck typing for Part-like objects
                        temp_parts.append(item.text)
                    else:
                        temp_parts.append(str(item))
                prompt_text_for_mock = "".join(temp_parts)

            print(f"  MockGeminiClient.generate_text í˜¸ì¶œë¨ (ëª¨ë¸: {model_name}). Mock í˜„ì¬ í‚¤: {self.mock_current_api_key[:5] if self.mock_current_api_key else 'N/A'}")

            if "ì•ˆì „ ë¬¸ì œ" in prompt_text_for_mock:
                raise GeminiContentSafetyException("Mock ì½˜í…ì¸  ì•ˆì „ ë¬¸ì œ")
            if "ì‚¬ìš©ëŸ‰ ì œí•œ" in prompt_text_for_mock: # Simplified logic for mock
                raise GeminiRateLimitException("Mock API ì‚¬ìš©ëŸ‰ ì œí•œ")
            if "ì˜ëª»ëœ ìš”ì²­" in prompt_text_for_mock:
                raise GeminiInvalidRequestException("Mock ì˜ëª»ëœ ìš”ì²­")

            text_to_be_translated = prompt_text_for_mock
            if "ë²ˆì—­í•  í…ìŠ¤íŠ¸:\n" in prompt_text_for_mock:
                text_to_be_translated = prompt_text_for_mock.split("ë²ˆì—­í•  í…ìŠ¤íŠ¸:\n")[-1].strip()
            elif "Translate to Korean:" in prompt_text_for_mock:
                 text_to_be_translated = prompt_text_for_mock.split("Translate to Korean:")[-1].strip()

            mock_translation = f"[ë²ˆì—­ë¨] {text_to_be_translated[:50]}..."

            is_json_response_expected = generation_config_dict and \
                                        generation_config_dict.get("response_mime_type") == "application/json"

            if is_json_response_expected:
                return {"translated_text": mock_translation, "mock_json": True}
            else:
                return mock_translation

        def list_models(self) -> List[Dict[str, Any]]:
            print("  MockGeminiClient.list_models í˜¸ì¶œë¨")
            # Return a structure similar to what GeminiClient.list_models would return
            return [
                {"name": "models/mock-gemini-flash", "short_name": "mock-gemini-flash", "display_name": "Mock Gemini Flash", "description": "A mock flash model.", "input_token_limit": 1000, "output_token_limit": 1000},
                {"name": "models/mock-gemini-pro", "short_name": "mock-gemini-pro", "display_name": "Mock Gemini Pro", "description": "A mock pro model.", "input_token_limit": 2000, "output_token_limit": 2000},
            ]

    sample_config_base = {
        "model_name": "gemini-1.5-flash", "temperature": 0.7, "top_p": 0.9,
        "prompts": "ë‹¤ìŒ í…ìŠ¤íŠ¸ë¥¼ í•œêµ­ì–´ë¡œ ë²ˆì—­í•´ì£¼ì„¸ìš”. ìš©ì–´ì§‘ ì»¨í…ìŠ¤íŠ¸: {{glossary_context}}\n\në²ˆì—­í•  í…ìŠ¤íŠ¸:\n{{slot}}",
        "enable_dynamic_glossary_injection": True, # í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•´ í™œì„±í™”
        "glossary_json_path": "test_glossary.json", # í†µí•©ëœ ìš©ì–´ì§‘ ê²½ë¡œ
        "max_glossary_entries_per_chunk_injection": 3,
        "max_glossary_chars_per_chunk_injection": 200,
    }

    # 1. ìš©ì–´ì§‘ ì£¼ì… í…ŒìŠ¤íŠ¸
    print("\n--- 1. ìš©ì–´ì§‘ ì£¼ì… ë²ˆì—­ í…ŒìŠ¤íŠ¸ ---")
    config1 = sample_config_base.copy()
    
    # í…ŒìŠ¤íŠ¸ìš© ìš©ì–´ì§‘ íŒŒì¼ ìƒì„±
    test_glossary_data = [
        {"keyword": "Alice", "translated_keyword": "ì•¨ë¦¬ìŠ¤", "source_language": "en", "target_language": "ko", "occurrence_count": 10},
        {"keyword": "Bob", "translated_keyword": "ë°¥", "source_language": "en", "target_language": "ko", "occurrence_count": 8}
    ]
    from infrastructure.file_handler import write_json_file, delete_file
    test_glossary_file = Path(config1["glossary_json_path"]) # Use path from config
    if test_glossary_file.exists(): delete_file(test_glossary_file)
    write_json_file(test_glossary_file, test_glossary_data)

    gemini_client_instance = MockGeminiClient(auth_credentials="dummy_api_key")
    translation_service1 = TranslationService(gemini_client_instance, config1)
    text_to_translate1 = "Hello Alice, how are you Bob?"
    try:
        translated1 = translation_service1.translate_text(text_to_translate1)
        print(f"  ì›ë³¸: {text_to_translate1}")
        print(f"  ë²ˆì—­ ê²°ê³¼: {translated1}")
    except Exception as e:
        print(f"  í…ŒìŠ¤íŠ¸ 1 ì˜¤ë¥˜: {e}")
    finally:
        if test_glossary_file.exists(): delete_file(test_glossary_file)

    # 2. ë¡œì–´ë¶ ë¹„í™œì„±í™” í…ŒìŠ¤íŠ¸
    print("\n--- 2. ë¡œì–´ë¶ ë¹„í™œì„±í™” í…ŒìŠ¤íŠ¸ ---")
    config2 = sample_config_base.copy()
    config2["enable_dynamic_lorebook_injection"] = False
    translation_service2 = TranslationService(gemini_client_instance, config2)
    text_to_translate2 = "This is a test sentence."
    try:
        translated2 = translation_service2.translate_text(text_to_translate2)
        print(f"ì›ë³¸: {text_to_translate2}")
        print(f"ë²ˆì—­ ê²°ê³¼: {translated2}")
    except Exception as e:
        print(f"í…ŒìŠ¤íŠ¸ 2 ì˜¤ë¥˜: {e}")

    # 3. ì½˜í…ì¸  ì•ˆì „ ë¬¸ì œ í…ŒìŠ¤íŠ¸
    print("\n--- 3. ì½˜í…ì¸  ì•ˆì „ ë¬¸ì œ í…ŒìŠ¤íŠ¸ ---")
    config3 = sample_config_base.copy()
    translation_service3 = TranslationService(gemini_client_instance, config3)
    text_unsafe = "ì•ˆì „ ë¬¸ì œ í…ŒìŠ¤íŠ¸ìš© í…ìŠ¤íŠ¸"
    try:
        translation_service3.translate_text(text_unsafe)
    except BtgTranslationException as e:
        print(f"ì˜ˆìƒëœ ì˜ˆì™¸ ë°œìƒ (ì½˜í…ì¸  ì•ˆì „): {e}")
    except Exception as e:
        print(f"í…ŒìŠ¤íŠ¸ 3 ì˜¤ë¥˜: {type(e).__name__} - {e}")

    print("\n--- TranslationService í…ŒìŠ¤íŠ¸ ì¢…ë£Œ ---")
